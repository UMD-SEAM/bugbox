% -------------------------------------------------------------------------
% This BibTex file was generated by Qiqqa (http://www.qiqqa.com/?ref=EXPBIB)
% Thursday, June 27, 2013 9:44:59 PM
% Version 3
% -------------------------------------------------------------------------

@misc{webgoat
,	title	= {OWASP WebGoat}
,	author	= {Open Web Application Security Project}
,	year	= {2013}
,	howpublished	= {https://code.google.com/p/webgoat/}
}

@ONLINE{WhiteHat:2010:Online,
author = {WhiteHat},
title = {Website Security Statistic Report 9th Edition retrieved from https://www.whitehatsec.com/assets/WPstats\_spring10\_9th.pdf},
month = Spring,
year = {2010},
url = {https://www.whitehatsec.com/assets/WPstats_spring10_9th.pdf}
}

@article{QIQQA-CSEHG
,	author	= {Tim  Boland}
,	title	= {}
,	year	= {2011}
,	publisher	= {}
}

@article{QIQQA-VSSGJ
,	author	= {Modeling Software Vulnerabilities With Vulnerability Cause Graphs}
,	title	= {}
,	year	= {2006}
,	publisher	= {}
}

@article{stuckman2011analyzing,
  title={Analyzing the wikisphere: Methodology and data to support quantitative wiki research},
  author={Stuckman, Jeffrey and Purtilo, James},
  journal={Journal of the American Society for Information Science and Technology},
  volume={62},
  number={8},
  pages={1564--1576},
  year={2011},
  publisher={Wiley Online Library}
}

@article{bessey2010few,
  title={A few billion lines of code later: using static analysis to find bugs in the real world},
  author={Bessey, Al and Block, Ken and Chelf, Ben and Chou, Andy and Fulton, Bryan and Hallem, Seth and Henri-Gros, Charles and Kamsky, Asya and McPeak, Scott and Engler, Dawson},
  journal={Communications of the ACM},
  volume={53},
  number={2},
  pages={66--75},
  year={2010},
  publisher={ACM}
}

@inproceedings{shahriar2010classification,
  title={Classification of Static Analysis-based Buffer Overflow Detectors},
  author={Shahriar, Hossain and Zulkernine, Mohammad},
  booktitle={Secure Software Integration and Reliability Improvement Companion (SSIRI-C), 2010 Fourth International Conference on},
  pages={94--101},
  year={2010},
  organization={IEEE}
}

@inproceedings{antunes2009comparing,
  title={Comparing the effectiveness of penetration testing and static code analysis on the detection of sql injection vulnerabilities in web services},
  author={Antunes, Nuno and Vieira, Marco},
  booktitle={Dependable Computing, 2009. PRDC'09. 15th IEEE Pacific Rim International Symposium on},
  pages={301--306},
  year={2009},
  organization={IEEE}
}

@article{QIQQA-JYVZL
,	author	= {Manuel Rudolph, Reinhard Schwarz}
,	title	= {}
,	year	= {2012}
,	publisher	= {}
}

@article{QIQQA-CBPCQ
,	author	= {Software Engineering Standards Committee of the IEEE Computer Society}
,	title	= {}
,	year	= {1998}
,	publisher	= {}
}

@article{QIQQA-FXZND
,	author	= {untitled}
,	title	= {}
,	year	= {2012}
,	publisher	= {}
}

@inproceedings{mantyla2012many,
  title={How many individuals to use in a QA task with fixed total effort?},
  author={M{\"a}ntyl{\"a}, Mika V and Petersen, Kai and Pfahl, Dietmar},
  booktitle={Proceedings of the ACM-IEEE international symposium on Empirical software engineering and measurement},
  pages={311--314},
  year={2012},
  organization={ACM}
}

@article{QIQQA-RGCES
,	author	= {C:\Users\Jeff\Downloads\SPIP-HYBRID.pdf}
,	title	= {}
,	year	= {2006}
,	publisher	= {}
}

@article{QIQQA-CTWEE
,	author	= {Equivalence hypothesis testing in experimental  software engineering}
,	title	= {}
,	year	= {2013}
,	publisher	= {}
}

@article{QIQQA-WCCSK
,	author	= {Evaluating software product metrics with synthetic  defect data}
,	title	= {}
,	year	= {2013}
,	publisher	= {}
}

@inproceedings{bugbox
,	author	= {Nilson, Gary and Wills, Kent and Stuckman, Jeffrey and Purtilo, James}
,	title	= {BugBox: A Vulnerability Corpus for PHP Web Applications}
,	booktitle	= {(To Appear) Proceedings of CSET 2013: The 6th USENIX Workshop on Cyber Security Experimentation and Test}
,	year	= {2013}
}

@misc{jhawk
,	title	= {JHawk -- The Java Metrics Tol}
,	url	= {http://www.virtualmachinery.com/jhawkprod.htm}
}

@article{shin2013can,
  title={Can traditional fault prediction models be used for vulnerability prediction?},
  author={Shin, Yonghee and Williams, Laurie},
  journal={Empirical Software Engineering},
  volume={18},
  number={1},
  pages={25--59},
  year={2013},
  publisher={Springer}
}

@article{QIQQA-EZYBN
,	author	= {Peter G. Hamer and Gllllan D. Frewln  Standard Telecommunication Laboratories Limited}
,	title	= {}
,	year	= {2000}
,	publisher	= {}
}

@MISC {MO6199,    
    TITLE = {{E}xpected value of a gamma-distributed random variable to the n-th power?},    
    AUTHOR = {John D. Cook},    
    HOWPUBLISHED = {MathOverflow},    
    NOTE = {\url{http://mathoverflow.net/questions/6199} (version: 2009-11-20)},    
    EPRINT = {\url{http://mathoverflow.net/questions/6199}},    
    URL = {\url{http://mathoverflow.net/questions/6199}},    
}

@inproceedings{chatzidiamantis2009distribution,
  title={On the distribution of the sum of gamma-gamma variates and application in MIMO optical wireless systems},
  author={Chatzidiamantis, Nestor D and Karagiannidis, George K and Michalopoulos, Diomidis S},
  booktitle={Global Telecommunications Conference, 2009. GLOBECOM 2009. IEEE},
  pages={1--6},
  year={2009},
  organization={IEEE}
}

@inproceedings{clark2004primer,
  title={A primer on the exponential family of distributions},
  author={Clark, David R and Thayer, Charles A},
  booktitle={Casualty Actuarial Society Spring Forum},
  pages={117--148},
  year={2004}
}

@misc{dispers
,	title	= {The Dispersion Parameter}
}

@misc{glmbook
,	howpublished	= {http://www.sagepub.com/upm-data/21121_Chapter_15.pdf}
,	title	= {Generalized Linear Models}
}

@misc{glmtheory
,	howpublished	= {http://data.princeton.edu/wws509/notes/a2.pdf}
}

@inproceedings{hazardevanco
,	author	= {Evanco, William M}
,	title	= {Using a proportional hazards model to analyze software reliability}
,	booktitle	= {Software Technology and Engineering Practice, 1999. STEP'99. Proceedings}
,	year	= {1999}
,	pages	= {134--141}
,	organization	= {IEEE}
}

@inproceedings{defectcorpus
,	author	= {D'Ambros, Marco and Lanza, Michele and Robbes, Romain}
,	title	= {An extensive comparison of bug prediction approaches}
,	booktitle	= {Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on}
,	year	= {2010}
,	pages	= {31--41}
,	organization	= {IEEE}
}

@inproceedings{shibata2006metrics,
  title={Metrics-based software reliability models using non-homogeneous Poisson processes},
  author={Shibata, Kazuya and Rinsaka, Koichiro and Dohi, Tadashi},
  booktitle={Software Reliability Engineering, 2006. ISSRE'06. 17th International Symposium on},
  pages={52--61},
  year={2006},
  organization={IEEE}
}

@inproceedings{ichii2008exploration,
  title={An exploration of power-law in use-relation of java software systems},
  author={Ichii, Makoto and Matsushita, Makoto and Inoue, Katsuro},
  booktitle={Software Engineering, 2008. ASWEC 2008. 19th Australian Conference on},
  pages={422--431},
  year={2008},
  organization={IEEE}
}

@inproceedings{baxter2006understanding,
  title={Understanding the shape of Java software},
  author={Baxter, Gareth and Frean, Marcus and Noble, James and Rickerby, Mark and Smith, Hayden and Visser, Matt and Melton, Hayden and Tempero, Ewan},
  booktitle={ACM SIGPLAN Notices},
  volume={41},
  number={10},
  pages={397--412},
  year={2006},
  organization={ACM}
}

@inproceedings{jing2006scale,
  title={Scale free in software metrics},
  author={Jing, Liu and Keqing, He and Yutao, Ma and Rong, Peng},
  booktitle={Computer Software and Applications Conference, 2006. COMPSAC'06. 30th Annual International},
  volume={1},
  pages={229--235},
  year={2006},
  organization={IEEE}
}

@inproceedings{wheeldon2003power,
  title={Power law distributions in class relationships},
  author={Wheeldon, Richard and Counsell, Steve},
  booktitle={Source Code Analysis and Manipulation, 2003. Proceedings. Third IEEE International Workshop on},
  pages={45--54},
  year={2003},
  organization={IEEE}
}

@inproceedings{nasseri2010empirical,
  title={An Empirical Study of Fan-In and Fan-Out in Java OSS},
  author={Nasseri, E and Counsell, S and Tempero, E},
  booktitle={Software Engineering Research, Management and Applications (SERA), 2010 Eighth ACIS International Conference on},
  pages={36--41},
  year={2010},
  organization={IEEE}
}

@inproceedings{mubarak2009does,
  title={Does an 80: 20 rule apply to Java coupling?},
  author={Mubarak, Asma and Counsell, Steve and Hierons, R},
  booktitle={Proceedings of the International Conference on Evaluation and Assessment in Software Engineering, Keele, UK},
  year={2009}
}

@inproceedings{tonelli2011analysis,
  title={An analysis of SNA metrics on the Java Qualitas Corpus},
  author={Tonelli, Roberto and Concas, Giulio and Marchesi, Michele and Murgia, Alessandro},
  booktitle={Proceedings of the 4th India Software Engineering Conference},
  pages={205--213},
  year={2011},
  organization={ACM}
}

@inproceedings{tempero2010qualitas,
  title={The Qualitas Corpus: A curated collection of Java code for empirical studies},
  author={Tempero, Ewan and Anslow, Craig and Dietrich, Jens and Han, Ted and Li, Jing and Lumpe, Markus and Melton, Hayden and Noble, James},
  booktitle={Software Engineering Conference (APSEC), 2010 17th Asia Pacific},
  pages={336--345},
  year={2010},
  organization={IEEE}
}

@article{gyimothy2005empirical,
  title={Empirical validation of object-oriented metrics on open source software for fault prediction},
  author={Gyimothy, Tibor and Ferenc, Rudolf and Siket, Istvan},
  journal={Software Engineering, IEEE Transactions on},
  volume={31},
  number={10},
  pages={897--910},
  year={2005},
  publisher={IEEE}
}

@article{lei2003evaluation,
  title={Evaluation of several nonparametric bootstrap methods to estimate confidence intervals for software metrics},
  author={Lei, Skylar and Smith, Michael R},
  journal={Software Engineering, IEEE Transactions on},
  volume={29},
  number={11},
  pages={996--1004},
  year={2003},
  publisher={IEEE}
}

@inproceedings{shar2013mining,
  title={Mining SQL injection and cross site scripting vulnerabilities using hybrid program analysis},
  author={Shar, Lwin Khin and Tan, Hee Beng Kuan and Briand, Lionel C},
  booktitle={Proceedings of the 2013 International Conference on Software Engineering},
  pages={642--651},
  year={2013},
  organization={IEEE Press}
}

@inproceedings{zhou2011secure,
  title={Secure network provenance},
  author={Zhou, Wenchao and Fei, Qiong and Narayan, Arjun and Haeberlen, Andreas and Loo, Boon Thau and Sherr, Micah},
  booktitle={Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles},
  pages={295--310},
  year={2011},
  organization={ACM}
}

#

@inproceedings{nagy2009static,
  title={Static security analysis based on input-related software faults},
  author={Nagy, Csaba and Mancoridis, Spiros},
  booktitle={Software Maintenance and Reengineering, 2009. CSMR'09. 13th European Conference on},
  pages={37--46},
  year={2009},
  organization={IEEE}
}

#

@article{einarsson2008survivor,
  title={A survivor’s guide to Java program analysis with soot},
  author={Einarsson, Arni and Nielsen, Janus Dam},
  journal={BRICS, Department of Computer Science, University of Aarhus, Denmark},
  year={2008}
}

@misc{mcpt
,	title	= {Monte Carlo Permutation Tests}
}

@inproceedings{buyens2009resolving,
  title={Resolving least privilege violations in software architectures},
  author={Buyens, Koen and De Win, Bart and Joosen, Wouter},
  booktitle={Software Engineering for Secure Systems, 2009. SESS'09. ICSE Workshop on},
  pages={9--16},
  year={2009},
  organization={IEEE}
}

@book{shin2011investigating,
  title={Investigating complexity metrics as indicators of software vulnerability},
  author={Shin, Yonghee and Adviser-Vouk, Mladen},
  year={2011},
  publisher={North Carolina State University}
}

@inproceedings{morasca2009probability,
  title={A probability-based approach for measuring external attributes of software artifacts},
  author={Morasca, Sandro},
  booktitle={Empirical Software Engineering and Measurement, 2009. ESEM 2009. 3rd International Symposium on},
  pages={44--55},
  year={2009},
  organization={IEEE}
}

@article{kampf2012fluctuations,
  title={Fluctuations in Wikipedia access-rate and edit-event data},
  author={K{\"a}mpf, Mirko and Tismer, Sebastian and Kantelhardt, Jan W and Muchnik, Lev},
  journal={Physica A: Statistical Mechanics and its Applications},
  year={2012},
  publisher={Elsevier}
}

@Article{simctestrpackage
,	author	= {Axel Gandy}
,	title	= {R-package companion to Sequential Implementation of Monte Carlo Tests with Uniformly Bounded Resampling Risk}
,	journal	= {Journal of the American Statistical Association}
,	year	= {2009}
,	volume	= {104}
,	number	= {488}
,	pages	= {1504--1511}
}

@article{gandy2009sequential,
  title={Sequential implementation of Monte Carlo tests with uniformly bounded resampling risk},
  author={Gandy, Axel},
  journal={Journal of the American Statistical Association},
  volume={104},
  number={488},
  pages={1504--1511},
  year={2009},
  publisher={Taylor \& Francis}
}

#

#

@article{powerlaw
,	author	= {Clauset, Aaron and Shalizi, Cosma Rohilla and Newman, Mark EJ}
,	title	= {Power-law distributions in empirical data}
,	journal	= {SIAM review}
,	year	= {2009}
,	volume	= {51}
,	number	= {4}
,	pages	= {661--703}
,	publisher	= {SIAM}
}

@article{livshits2005defining,
  title={Defining a set of common benchmarks for web application security},
  author={Livshits, Benjamin},
  year={2005},
  publisher={Citeseer},
howpublished={doi:10.1.1.59.6723}
}

@mastersthesis{wikithesis
,	author	= {Jeffrey Stuckman}
,	title	= {Analyzing the Wikisphere: Tools and Methods for Wiki Research}
,	school	= {University of Maryland, College Park}
,	year	= {2010}
}

@INPROCEEDINGS{1408432, 
author={Alhazmi, O.H. and Malaiya, Y.K.}, 
booktitle={Reliability and Maintainability Symposium, 2005. Proceedings. Annual}, title={Quantitative vulnerability assessment of systems software}, 
year={2005}, 
pages={615-620}, 
abstract={Not Available}, 
keywords={operating systems (computers);security of data;software reliability;Windows 98;Windows NT 4.0;cumulative number;equivalent effort;operating system;quantitative vulnerability assessment;security risk;software reliability growth model;systems software;time-based model;Data security;Density measurement;Information security;Operating systems;Resource management;Software measurement;Software reliability;Software systems;System software;Testing}, 
doi={10.1109/RAMS.2005.1408432}, 
ISSN={0149-144X},}

@misc{cvecwe
,	howpublished	= {http://nvd.nist.gov/cwe.cfm}
,	title	= {CWE - Common Weakness Enumeration}
}

#

@incollection{centrality
,	author	= {Kosch\"utzki, Dirk and Lehmann, KatharinaAnna and Peeters, Leon and Richter, Stefan and Tenfelde-Podehl, Dagmar and Zlotowski, Oliver}
,	title	= {Centrality Indices}
,	booktitle	= {Network Analysis}
,	year	= {2005}
,	editor	= {Brandes, Ulrik and Erlebach, Thomas}
,	pages	= {16-61}
,	publisher	= {Springer Berlin Heidelberg}
,	isbn	= {978-3-540-24979-5}
,	volume	= {3418}
,	series	= {Lecture Notes in Computer Science}
,	doi	= {10.1007/978-3-540-31955-9_3}
,	url	= {http://dx.doi.org/10.1007/978-3-540-31955-9_3}
}

@misc{miscevc
,	title	= {Eigenvector Centrality}
}

#

@inproceedings{relationshipmetric
,	author	= {Henry, Sallie and Kafura, Dennis and Harris, Kathy}
,	title	= {On the relationships among three software metrics}
,	booktitle	= {ACM SIGMETRICS Performance Evaluation Review}
,	year	= {1981}
,	pages	= {81--88}
,	organization	= {ACM}
,	volume	= {10}
,	number	= {1}
}

@article{mccabe
,	author	= {McCabe, Thomas J.}
,	title	= {A complexity measure}
,	journal	= {Software Engineering, IEEE Transactions on}
,	year	= {1976}
,	number	= {4}
,	pages	= {308--320}
,	publisher	= {IEEE}
}

@article{haeberlen2007peerreview,
  title={PeerReview: Practical accountability for distributed systems},
  author={Haeberlen, Andreas and Kouznetsov, Petr and Druschel, Peter},
  journal={ACM SIGOPS Operating Systems Review},
  volume={41},
  number={6},
  pages={175--188},
  year={2007},
  publisher={ACM}
}

@inproceedings{initialexec
,	author	= {Shin, Yonghee and Williams, Laurie}
,	title	= {An initial study on the use of execution complexity metrics as indicators of software vulnerabilities}
,	booktitle	= {Proceedings of the 7th International Workshop on Software Engineering for Secure Systems}
,	year	= {2011}
,	pages	= {1--7}
,	organization	= {ACM}
}

#

@phdthesis{meek2012degree
,	author	= {Meek, Joshua A}
,	title	= {M.I.D.A.S. Metrics Identification of Attack Surfaces}
,	school	= {BALL STATE UNIVERSITY}
,	year	= {2012}
}

@article{empiricalinvestigation
,	author	= {Huynh, T. and Miller, J.}
,	title	= {An empirical investigation into open source web applications’ implementation vulnerabilities}
,	journal	= {Empirical Software Engineering}
,	year	= {2010}
,	volume	= {15}
,	number	= {5}
,	pages	= {556--576}
,	publisher	= {Springer}
}

@article{hafiz2009catalog,
  title={A catalog of security-oriented program transformations},
  author={Hafiz, Munawar and Adamczyk, Paul and Johnson, Ralph},
  journal={Submitted to ECOOP 2009},
  year={2009}
}

@inproceedings{buyens2009identifying,
  title={Identifying and resolving least privilege violations in software architectures},
  author={Buyens, Koen and De Win, Bart and Joosen, Wouter},
  booktitle={Availability, Reliability and Security, 2009. ARES'09. International Conference on},
  pages={232--239},
  year={2009},
  organization={IEEE}
}

@inproceedings{shankar2006toward,
  title={Toward automated information-flow integrity verification for security-critical applications},
  author={Shankar, U. and Jaeger, T. and Sailer, R.},
  booktitle={Proceedings of the 2006 ISOC Networked and Distributed Systems Security Symposium},
  year={2006},
  organization={Citeseer}
}

@inproceedings{vijayakumar2012sting,
  title={STING: finding name resolution vulnerabilities in programs},
  author={Vijayakumar, H. and Schiffman, J. and Jaeger, T.},
  booktitle={Proceedings of the 21st USENIX Security Symposium (USENIX Security 2012)},
  year={2012}
}

@inproceedings{muthukumaran2012leveraging,
  title={Leveraging choice to automate authorization hook placement},
  author={Muthukumaran, Divya and Jaeger, Trent and Ganapathy, Vinod},
  booktitle={Proceedings of the 2012 ACM conference on Computer and communications security},
  pages={145--156},
  year={2012},
  organization={ACM}
}

@techreport{measuringarch
,	author	= {Gennari, Jeffrey and Garlan, David}
,	title	= {Measuring Attack Surface in Software Architecture}
,	institution	= {Technical Report CMU-ISR-11-121, Carnegie Mellon University}
,	year	= {2012}
}

#

@inproceedings{el2009intrusion,
  title={Intrusion detection using signatures extracted from execution profiles},
  author={El-Ghali, Marwa and Masri, Wes},
  booktitle={Software Engineering for Secure Systems, 2009. SESS'09. ICSE Workshop on},
  pages={17--24},
  year={2009},
  organization={IEEE}
}

@inproceedings{samuel2011context,
  title={Context-sensitive auto-sanitization in web templating languages using type qualifiers},
  author={Samuel, Mike and Saxena, Prateek and Song, Dawn},
  booktitle={Proceedings of the 18th ACM conference on Computer and communications security},
  pages={587--600},
  year={2011},
  organization={ACM}
}

#

@inproceedings{wang2008towards,
  title={Towards automatic reverse engineering of software security configurations},
  author={Wang, Rui and Wang, XiaoFeng and Zhang, Kehuan and Li, Zhuowei},
  booktitle={Proceedings of the 15th ACM conference on Computer and communications security},
  pages={245--256},
  year={2008},
  organization={ACM}
}

@inproceedings{newsome2006replayer,
  title={Replayer: Automatic protocol replay by binary analysis},
  author={Newsome, James and Brumley, David and Franklin, Jason and Song, Dawn},
  booktitle={Proceedings of the 13th ACM conference on Computer and communications security},
  pages={311--321},
  year={2006},
  organization={ACM}
}

@inproceedings{moser2007exploring,
  title={Exploring multiple execution paths for malware analysis},
  author={Moser, Andreas and Kruegel, Christopher and Kirda, Engin},
  booktitle={Security and Privacy, 2007. SP'07. IEEE Symposium on},
  pages={231--245},
  year={2007},
  organization={IEEE}
}

@misc{dumbpatch
,	title	= {Story of a dumb patch}
,	howpublished	= {http://www.scn.rain.com/~neighorn/PDF/MSBugPaper.pdf}
}

@ARTICLE{1668014, 
author={Bellovin, S.M.}, 
journal={Security Privacy, IEEE}, title={On the Brittleness of Software and the Infeasibility of Security Metrics}, 
year={2006}, 
month={july-aug.}, 
volume={4}, 
number={4}, 
pages={ 96}, 
abstract={ How secure is a computer system? Bridges have a load limit, but it isn't determined (as "Calvin and Hobbes" would have it) by building an identical bridge and running trucks over it until it collapses. In a more relevant vein, safes are rated for how long they'll resist attack under given circumstances. Can we do the same for software?}, 
keywords={ defense; defense systems; security; software;}, 
doi={10.1109/MSP.2006.101}, 
ISSN={1540-7993},}

@inproceedings{Gegick:2009:TNF:1532731.1532747,
 author = {Gegick, Michael and Rotella, Pete and Williams, Laurie},
 title = {Toward Non-security Failures as a Predictor of Security Faults and Failures},
 booktitle = {Proceedings of the 1st International Symposium on Engineering Secure Software and Systems},
 series = {ESSoS '09},
 year = {2009},
 isbn = {978-3-642-00198-7},
 location = {Leuven, Belgium},
 pages = {135--149},
 numpages = {15},
 url = {http://dx.doi.org/10.1007/978-3-642-00199-4_12},
 doi = {10.1007/978-3-642-00199-4_12},
 acmid = {1532747},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {Attack-prone, classification and regression tree},
} 


@inproceedings{prioritizingfortification
,	author	= {Gegick, Michael and Williams, Laurie and Osborne, Jason and Vouk, Mladen}
,	title	= {Prioritizing software security fortification through code-level metrics}
,	booktitle	= {Proceedings of the 4th ACM workshop on Quality of protection}
,	year	= {2008}
,	pages	= {31--38}
,	publisher	= {ACM}
,	address	= {New York, NY, USA}
,	series	= {QoP '08}
,	isbn	= {978-1-60558-321-1}
,	location	= {Alexandria, Virginia, USA}
,	numpages	= {8}
,	url	= {http://doi.acm.org/10.1145/1456362.1456370}
,	doi	= {10.1145/1456362.1456370}
,	acmid	= {1456370}
,	keywords	= {attack-prone, vulnerability-prone}
}

@inproceedings{complexityenemy
,	author	= {Shin, Yonghee and Williams, Laurie}
,	title	= {Is complexity really the enemy of software security?}
,	booktitle	= {Proceedings of the 4th ACM workshop on Quality of protection}
,	year	= {2008}
,	pages	= {47--50}
,	publisher	= {ACM}
,	address	= {New York, NY, USA}
,	series	= {QoP '08}
,	isbn	= {978-1-60558-321-1}
,	location	= {Alexandria, Virginia, USA}
,	numpages	= {4}
,	url	= {http://doi.acm.org/10.1145/1456362.1456372}
,	doi	= {10.1145/1456362.1456372}
,	acmid	= {1456372}
,	keywords	= {fault prediction, reliability, security metrics, software complexity, software metrics, vulnerability prediction}
}

@article{Poels200035,
title = "Distance-based software measurement: necessary and sufficient properties for software measures",
journal = "Information and Software Technology",
volume = "42",
number = "1",
pages = "35 - 46",
year = "2000",
note = "",
issn = "0950-5849",
doi = "10.1016/S0950-5849(99)00053-1",
url = "http://www.sciencedirect.com/science/article/pii/S0950584999000531",
author = "G. Poels and G. Dedene",
keywords = "Software metric",
keywords = "Axiomatic approach",
keywords = "Measure validation",
keywords = "Measurement theory",
abstract = "Axiomatic approaches to software measurement present sets of necessary, but not sufficient measure axioms. The insufficiency of the measure axioms implies that they are useful to invalidate existing software measures, but not to validate them. In this paper, a set of measure axioms is presented whose sufficiency is guaranteed by measurement theory. The axioms referred to are the metric axioms, used in mathematics to define measures of distance. We present a constructive procedure that defines software measures satisfying these axioms. As an illustration of distance-based software measurement, a measure is defined for the aggregation coupling of object classes."
}


@inproceedings{refiningaxiomatic
,	author	= {Morasca, Sandro}
,	title	= {Refining the axiomatic definition of internal software attributes}
,	booktitle	= {Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement}
,	year	= {2008}
,	pages	= {188--197}
,	publisher	= {ACM}
,	address	= {New York, NY, USA}
,	series	= {ESEM '08}
,	isbn	= {978-1-59593-971-5}
,	location	= {Kaiserslautern, Germany}
,	numpages	= {10}
,	url	= {http://doi.acm.org/10.1145/1414004.1414035}
,	doi	= {10.1145/1414004.1414035}
,	acmid	= {1414035}
,	keywords	= {cohesion, complexity, coupling, internal software attributes, size}
}

@ARTICLE{propertybased
,	author	= {Briand, L.C. and Morasca, S. and Basili, V.R.}
,	title	= {Property-based software engineering measurement}
,	journal	= {Software Engineering, IEEE Transactions on}
,	year	= {1996}
,	volume	= {22}
,	number	= {1}
,	pages	= {68 -86}
,	month	= {jan}
,	abstract	= {Little theory exists in the field of software system measurement. Concepts such as complexity, coupling, cohesion or even size are very often subject to interpretation and appear to have inconsistent definitions in the literature. As a consequence, there is little guidance provided to the analyst attempting to define proper measures for specific problems. Many controversies in the literature are simply misunderstandings and stem from the fact that some people talk about different measurement concepts under the same label (complexity is the most common case). There is a need to define unambiguously the most important measurement concepts used in the measurement of software products. One way of doing so is to define precisely what mathematical properties characterize these concepts, regardless of the specific software artifacts to which these concepts are applied. Such a mathematical framework could generate a consensus in the software engineering community and provide a means for better communication among researchers, better guidelines for analysts, and better evaluation methods for commercial static analyzers for practitioners. We propose a mathematical framework which is generic, because it is not specific to any particular software artifact, and rigorous, because it is based on precise mathematical concepts. We use this framework to propose definitions of several important measurement concepts (size, length, complexity, cohesion, coupling). It does not intend to be complete or fully objective; other frameworks could have been proposed and different choices could have been made. However, we believe that the formalisms and properties we introduce are convenient and intuitive. This framework contributes constructively to a firmer theoretical ground of software measurement}
,	keywords	= {cohesion;commercial static analyzers;complexity;coupling;evaluation methods;mathematical properties;property-based software engineering measurement;software products;software system measurement;computational complexity;software metrics;system monitoring;}
,	doi	= {10.1109/32.481535}
,	issn	= {0098-5589}
}

@inproceedings{evaluatingcost
,	author	= {Baca, Dejan and Carlsson, Bengt and Lundberg, Lars}
,	title	= {Evaluating the cost reduction of static code analysis for software security}
,	booktitle	= {Proceedings of the third ACM SIGPLAN workshop on Programming languages and analysis for security}
,	year	= {2008}
,	pages	= {79--88}
,	publisher	= {ACM}
,	address	= {New York, NY, USA}
,	series	= {PLAS '08}
,	isbn	= {978-1-59593-936-4}
,	location	= {Tucson, AZ, USA}
,	numpages	= {10}
,	url	= {http://doi.acm.org/10.1145/1375696.1375707}
,	doi	= {10.1145/1375696.1375707}
,	acmid	= {1375707}
,	keywords	= {cost reduction, coverity prevent, early fault detection, false positive, security, source code, static code analysis, trouble report}
}

@ARTICLE{validationobject
,	author	= {Basili, V.R. and Briand, L.C. and Melo, W.L.}
,	title	= {A validation of object-oriented design metrics as quality indicators}
,	journal	= {Software Engineering, IEEE Transactions on}
,	year	= {1996}
,	volume	= {22}
,	number	= {10}
,	pages	= {751 -761}
,	month	= {oct}
,	abstract	= {This paper presents the results of a study in which we empirically investigated the suite of object-oriented (OO) design metrics introduced in (Chidamber and Kemerer, 1994). More specifically, our goal is to assess these metrics as predictors of fault-prone classes and, therefore, determine whether they can be used as early quality indicators. This study is complementary to the work described in (Li and Henry, 1993) where the same suite of metrics had been used to assess frequencies of maintenance changes to classes. To perform our validation accurately, we collected data on the development of eight medium-sized information management systems based on identical requirements. All eight projects were developed using a sequential life cycle model, a well-known OO analysis/design method and the C++ programming language. Based on empirical and quantitative analysis, the advantages and drawbacks of these OO metrics are discussed. Several of Chidamber and Kemerer's OO metrics appear to be useful to predict class fault-proneness during the early phases of the life-cycle. Also, on our data set, they are better predictors than ldquo;traditional rdquo; code metrics, which can only be collected at a later phase of the software development processes}
,	keywords	= {C++ programming language;class maintenance changes;data set;fault-prone classes;information management systems;metric validation;object oriented analysis;object-oriented design metrics;sequential life cycle model;software development;software quality indicators;C language;information systems;object-oriented languages;object-oriented methods;software maintenance;software metrics;software quality;}
,	doi	= {10.1109/32.544352}
,	issn	= {0098-5589}
}

@ARTICLE{designmetriceval
,	author	= {Kitchenham, B.A. and Pickard, L.M. and Linkman, S.J.}
,	title	= {An evaluation of some design metrics}
,	journal	= {Software Engineering Journal}
,	year	= {1990}
,	volume	= {5}
,	number	= {1}
,	pages	= {50 -58}
,	month	= {jan}
,	abstract	= {Some software design metrics are evaluated using data from a communications system. The design metrics investigated were based on the information flow metrics proposed by S. Henry and D. Kafura (1981) and the problems they encountered are discussed. The slightly simpler metrics used in this study are described. The ability of the design metrics to identify change-prone, error-prone and complex programs are contrasted with that of simple code metrics. Although one of the design metrics (informational fan-out)/ was able to identify change-prone, fault-prone and complex programs, code metrics (i.e. lines of code and number of branches) were better. In this context `better' means correctly identifying a larger proportion of change-prone, error-prone and/or complex programs, while maintaining a relatively low false identification rate (i.e. incorrectly identifying a program which did not in fact exhibit any undesirable features)}
,	keywords	= {change-prone;code metrics;communications system;complex programs;error-prone;information flow metrics;informational fan-out;low false identification rate;software design metrics;performance evaluation;software engineering;}
,	issn	= {0268-6961}
}

@ARTICLE{prelimguidelines
,	author	= {Kitchenham, B.A. and Pfleeger, S.L. and Pickard, L.M. and Jones, P.W. and Hoaglin, D.C. and El Emam, K. and Rosenberg, J.}
,	title	= {Preliminary guidelines for empirical research in software engineering}
,	journal	= {Software Engineering, IEEE Transactions on}
,	year	= {2002}
,	volume	= {28}
,	number	= {8}
,	pages	= { 721 - 734}
,	month	= {aug}
,	abstract	= { Empirical software engineering research needs research guidelines to improve the research and reporting processes. We propose a preliminary set of research guidelines aimed at stimulating discussion among software researchers. They are based on a review of research guidelines developed for medical researchers and on our own experience in doing and reviewing software engineering research. The guidelines are intended to assist researchers, reviewers, and meta-analysts in designing, conducting, and evaluating empirical studies. Editorial boards of software engineering journals may wish to use our recommendations as a basis for developing guidelines for reviewers and for framing policies for dealing with the design, data collection, and analysis and reporting of empirical studies.}
,	keywords	= { software engineering; software researchers; software engineering;}
,	doi	= {10.1109/TSE.2002.1027796}
,	issn	= {0098-5589}
}

@ARTICLE{frameworkvalidation
,	author	= {Kitchenham, B. and Pfleeger, S.L. and Fenton, N.}
,	title	= {Towards a framework for software measurement validation}
,	journal	= {Software Engineering, IEEE Transactions on}
,	year	= {1995}
,	volume	= {21}
,	number	= {12}
,	pages	= {929 -944}
,	month	= {dec}
,	abstract	= {In this paper we propose a framework for validating software measurement. We start by defining a measurement structure model that identifies the elementary component of measures and the measurement process, and then consider five other models involved in measurement: unit definition models, instrumentation models, attribute relationship models, measurement protocols and entity population models. We consider a number of measures from the viewpoint of our measurement validation framework and identify a number of shortcomings; in particular we identify a number of problems with the construction of function points. We also compare our view of measurement validation with ideas presented by other researchers and identify a number of areas of disagreement. Finally, we suggest several rules that practitioners and researchers can use to avoid measurement problems, including the use of measurement vectors rather than artificially contrived scalars}
,	keywords	= {attribute relationship models;entity population models;framework;instrumentation models;measurement process;measurement protocols;measurement structure model;measurement vectors;measures;software measurement validation;unit definition models;measurement theory;software metrics;}
,	doi	= {10.1109/32.489070}
,	issn	= {0098-5589}
}

@ARTICLE{scientificbasis
,	author	= {Fenton, N.}
,	title	= {Software measurement: a necessary scientific basis}
,	journal	= {Software Engineering, IEEE Transactions on}
,	year	= {1994}
,	volume	= {20}
,	number	= {3}
,	pages	= {199 -206}
,	month	= {mar}
,	abstract	= {Software measurement, like measurement in any other discipline, must adhere to the science of measurement if it is to gain widespread acceptance and validity. The observation of some very simple, but fundamental, principles of measurement can have an extremely beneficial effect on the subject. Measurement theory is used to highlight both weaknesses and strengths of software metrics work, including work on metrics validation. We identify a problem with the well-known Weyuker properties (E.J. Weyuker, 1988), but also show that a criticism of these properties by J.C. Cherniavsky and C.H. Smith (1991) is invalid. We show that the search for general software complexity measures is doomed to failure. However, the theory does help us to define and validate measures of specific complexity attributes. Above all, we are able to view software measurement in a very wide perspective, rationalising and relating its many diverse activities}
,	keywords	= {complexity attributes;measurement theory;metrics validation;scientific basis;software complexity measures;software measurement;software metrics work;measurement theory;programming theory;software metrics;}
,	doi	= {10.1109/32.268921}
,	issn	= {0098-5589}
}

@ARTICLE{87287, 
author={Cherniavsky, J.C. and Smith, C.H.}, 
journal={Software Engineering, IEEE Transactions on}, title={On Weyuker's axioms for software complexity measures}, 
year={1991}, 
month={jun}, 
volume={17}, 
number={6}, 
pages={636 -638}, 
abstract={Properties for software complexity measures are discussed. It is shown that a collection of nine properties suggested by E.J. Weyuker is inadequate for determining the quality of a software complexity measure. (see ibid., vol.14, p.1357-65, 1988). A complexity measure which satisfies all nine of the properties, but which has absolutely no practical utility in measuring the complexity of a program is presented. It is concluded that satisfying all of the nine properties is a necessary, but not sufficient, condition for a good complexity measure }, 
keywords={software complexity measures;computational complexity;software metrics;}, 
doi={10.1109/32.87287}, 
ISSN={0098-5589},}

@ARTICLE{evaluatingsoftwarecomplexity
,	author	= {Weyuker, E.J.}
,	title	= {Evaluating software complexity measures}
,	journal	= {Software Engineering, IEEE Transactions on}
,	year	= {1988}
,	volume	= {14}
,	number	= {9}
,	pages	= {1357 -1365}
,	month	= {sep}
,	abstract	= {A set of properties of syntactic software complexity measures is proposed to serve as a basis for the evaluation of such measures. Four known complexity measures are evaluated and compared using these criteria. This formalized evaluation clarifies the strengths and weaknesses of the examined complexity measures, which include the statement count, cyclomatic number, effort measure, and data flow complexity measures. None of these measures possesses all nine properties, and several are found to fail to possess particularly fundamental properties; this failure calls into question their usefulness in measuring synthetic complexity}
,	keywords	= {cyclomatic number;data flow complexity;effort measure;software complexity measures;software engineering;statement count;syntactic software complexity;synthetic complexity;software engineering;}
,	doi	= {10.1109/32.6178}
,	issn	= {0098-5589}
}

@article{systematicreview
,	author	= {Cagatay Catal and Banu Diri}
,	title	= {A systematic review of software fault prediction studies}
,	journal	= {Expert Systems with Applications}
,	year	= {2009}
,	volume	= {36}
,	number	= {4}
,	pages	= {7346 - 7354}
,	issn	= {0957-4174}
,	doi	= {10.1016/j.eswa.2008.10.027}
,	url	= {http://www.sciencedirect.com/science/article/pii/S0957417408007215}
,	keywords	= {Expert systems}
,	abstract	= {This paper provides a systematic review of previous software fault prediction studies with a specific focus on metrics, methods, and datasets. The review uses 74 software fault prediction papers in 11 journals and several conference proceedings. According to the review results, the usage percentage of public datasets increased significantly and the usage percentage of machine learning algorithms increased slightly since 2005. In addition, method-level metrics are still the most dominant metrics in fault prediction research area and machine learning algorithms are still the most popular methods for fault prediction. Researchers working on software fault prediction area should continue to use public datasets and machine learning algorithms to build better fault predictors. The usage percentage of class-level is beyond acceptable levels and they should be used much more than they are now in order to predict the faults earlier in design phase of software life cycle.}
}

@inproceedings{boehmquant
,	author	= {Boehm, B. W. and Brown, J. R. and Lipow, M.}
,	title	= {Quantitative evaluation of software quality}
,	booktitle	= {Proceedings of the 2nd international conference on Software engineering}
,	year	= {1976}
,	pages	= {592--605}
,	publisher	= {IEEE Computer Society Press}
,	address	= {Los Alamitos, CA, USA}
,	series	= {ICSE '76}
,	location	= {San Francisco, California, United States}
,	numpages	= {14}
,	url	= {http://dl.acm.org/citation.cfm?id=800253.807736}
,	acmid	= {807736}
,	keywords	= {Management by objectives, Quality assurance, Quality characteristics, Quality metrics, Software engineering, Software measurement and evaluation, Software quality, Software reliability, Software standards, Testing}
}

@incollection {springerlink:10.1007/978-3-642-02633-1_2,
   author = {Savola, Reijo M.},
   affiliation = {VTT Technical Research Centre of Finland Kaitoväylä 1 90570 Oulu Finland},
   title = {A Security Metrics Development Method for Software Intensive Systems},
   booktitle = {Advances in Information Security and Its Application},
   series = {Communications in Computer and Information Science},
   editor = {Park, Jong Hyuk and Zhan, Justin and Lee, Changhoon and Wang, Guilin and Kim, Tai-hoon and Yeo, Sang-Soo},
   publisher = {Springer Berlin Heidelberg},
   isbn = {978-3-642-02633-1},
   keyword = {Computer Science},
   pages = {11-16},
   volume = {36},
   url = {http://dx.doi.org/10.1007/978-3-642-02633-1_2},
   note = {10.1007/978-3-642-02633-1_2},
   abstract = {It is a widely accepted management principle that an activity cannot be managed well if it cannot be measured. Carefully designed security metrics can be used to offer evidence of the security behavior of the system under development or operation. We propose a systematic and holistic method for security metrics development for software intensive systems. The approach is security requirement-centric and threat and vulnerability-driven. The high-level security requirements are expressed in terms of lower-level measurable components applying a decomposition approach. Next, feasibility of the basic measurable components is investigated, and more detailed metrics developed based on selected components.},
   year = {2009}
}

@inproceedings{Wang:2009:SMS:1566445.1566509,
 author = {Wang, Ju An and Wang, Hao and Guo, Minzhe and Xia, Min},
 title = {Security metrics for software systems},
 booktitle = {Proceedings of the 47th Annual Southeast Regional Conference},
 series = {ACM-SE 47},
 year = {2009},
 isbn = {978-1-60558-421-8},
 location = {Clemson, South Carolina},
 pages = {47:1--47:6},
 articleno = {47},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/1566445.1566509},
 doi = {10.1145/1566445.1566509},
 acmid = {1566509},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {security metrics, software quality, software security, software vulnerabilities},
} 


@inproceedings{faily2012model,
  title={Model-driven architectural risk analysis using architectural and contextualised attack patterns},
  author={Faily, Shamal and Lyle, John and Namiluko, Cornelius and Atzeni, Andrea and Cameroni, Cesare},
  booktitle={Proceedings of the Workshop on Model-Driven Security},
  pages={3},
  year={2012},
  organization={ACM}
}

@ARTICLE{savi
,	author	= {Walden, J. and Doyle, M.}
,	title	= {SAVI: Static-Analysis Vulnerability Indicator}
,	journal	= {Security Privacy, IEEE}
,	year	= {2012}
,	volume	= {10}
,	number	= {3}
,	pages	= {32 -39}
,	month	= {may-june }
,	abstract	= {Open source software presents new opportunities for software acquisition but introduces risks. The selection of open source applications should take into account both features and security risks. Risks include security vulnerabilities, of which published vulnerabilities are only the tip of the iceberg. Having an application's source code lets us look deeper at its security. SAVI (Static-Analysis Vulnerability Indicator) is a metric for assessing risks of using software built by external developers. It combines several types of static-analysis data to rank application vulnerability.}
,	keywords	= {SAVI;Web browsers;application vulnerability;external developers;open source software;security risks;security vulnerabilities;software acquisition;source code;static-analysis vulnerability indicator;program diagnostics;public domain software;security of data;}
,	doi	= {10.1109/MSP.2012.1}
,	issn	= {1540-7993}
}

@misc{attsurosstmm
,	title	= {Attack surface security metrics}
}

@inproceedings{textanalysis
,	author	= {Hovsepyan, A. and Scandariato, R. and Joosen, W. and Walden, J.}
,	title	= {Software vulnerability prediction using text analysis techniques}
,	booktitle	= {Proceedings of the 4th international workshop on Security measurements and metrics}
,	year	= {2012}
,	pages	= {7--10}
,	organization	= {ACM}
}

@article{predictingandroid
,	author	= {Scandariato, Riccardo and Walden, James}
,	title	= {Predicting Vulnerable Classes in an Android Application}
,	journal	= {status: published}
,	year	= {2012}
,	pages	= {1--6}
,	publisher	= {IEEE}
}

@article{trattexperimental,
  title={Experimental Assessment of Software Metrics Using Automated Refactoring},
  author={Tratt, Laurence and Harman, Mark and Counsell, Steve and Moghadam, Iman Hemati and Hemati, Iman}
}

@inproceedings{definitiondynamic
,	author	= {Lavazza, Luigi and Morasca, Sandro and Taibi, Davide and Tosi, Davide}
,	title	= {On the definition of dynamic software measures}
,	booktitle	= {Proceedings of the ACM-IEEE international symposium on Empirical software engineering and measurement}
,	year	= {2012}
,	pages	= {39--48}
,	organization	= {ACM}
}

@article{QIQQA-FNOYO
,	author	= {student}
,	title	= {}
,	year	= {2012}
,	publisher	= {}
}

@inproceedings{methodbug
,	author	= {Giger, Emanuel and D'Ambros, Marco and Pinzger, Martin and Gall, Harald C}
,	title	= {Method-level bug prediction}
,	booktitle	= {Proceedings of the ACM-IEEE international symposium on Empirical software engineering and measurement}
,	year	= {2012}
,	pages	= {171--180}
,	organization	= {ACM}
}

@article{evalcomplexityvul
,	author	= {Shin, Yonghee and Meneely, Andrew and Williams, Laurie and Osborne, Jason A}
,	title	= {Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities}
,	journal	= {Software Engineering, IEEE Transactions on}
,	year	= {2011}
,	volume	= {37}
,	number	= {6}
,	pages	= {772--787}
,	publisher	= {IEEE}
}

@inproceedings{Wassermann:2008:DTI:1390630.1390661,
 author = {Wassermann, Gary and Yu, Dachuan and Chander, Ajay and Dhurjati, Dinakar and Inamura, Hiroshi and Su, Zhendong},
 title = {Dynamic test input generation for web applications},
 booktitle = {Proceedings of the 2008 international symposium on Software testing and analysis},
 series = {ISSTA '08},
 year = {2008},
 isbn = {978-1-60558-050-0},
 location = {Seattle, WA, USA},
 pages = {249--260},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1390630.1390661},
 doi = {10.1145/1390630.1390661},
 acmid = {1390661},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {automatic test generation, concolic testing, directed random testing, web applications},
} 

@techreport{
,	title	= {Design and Implementation of a PHP Compiler Front-End}
}

@phdthesis{biggar2009design,
  title={Design and Implementation of an Ahead-of-Time Compiler for PHP},
  author={Biggar, P.},
  year={2009},
  school={TRINITY COLLEGE DUBLIN}
}

@incollection {springerlink:10.1007/978-3-642-24933-4_7,
   author = {Stehr, Mark-Oliver and Talcott, Carolyn and Rushby, John and Lincoln, Pat and Kim, Minyoung and Cheung, Steven and Poggio, Andy},
   affiliation = {SRI International, USA},
   title = {Fractionated Software for Networked Cyber-Physical Systems: Research Directions and Long-Term Vision},
   booktitle = {Formal Modeling: Actors, Open Systems, Biological Systems},
   series = {Lecture Notes in Computer Science},
   editor = {Agha, Gul and Danvy, Olivier and Meseguer, José},
   publisher = {Springer Berlin / Heidelberg},
   isbn = {978-3-642-24932-7},
   keyword = {Computer Science},
   pages = {110-143},
   volume = {7000},
   url = {http://dx.doi.org/10.1007/978-3-642-24933-4_7},
   note = {10.1007/978-3-642-24933-4_7},
   year = {2011}
}

@techreport{ajaxreport
,	author	= {Jeffrey Stuckman and James Purtilo}
,	title	= {Detecting runtime anomalies in AJAX applications through trace analysis}
,	institution	= {University of Maryland, College Park}
,	year	= {2011}
,	number	= {CS-TR-4989}
}

@INPROCEEDINGS{metrisec2012surface
,	author	= {Stuckman, J. and Purtilo, J.}
,	title	= {Comparing and Applying Attack Surface Metrics}
,	booktitle	= {Proceedings of MetriSec 2012: International Workshop on Security Measurements and Metrics}
,	year	= {2012}
}

@inproceedings{cadar2012multi,
  title={Multi-version software updates},
  author={Cadar, C and Hosek, P},
  booktitle={Hot Topics in Software Upgrades (HotSWUp), 2012 Fourth Workshop on},
  pages={36--40},
  year={2012},
  organization={IEEE}
}

@article{turpie2011multiotter,
  title={Multiotter: Multiprocess symbolic execution},
  author={Turpie, Jonathan and Reisner, Elnatan and Foster, Jeffrey S and Hicks, Michael},
  year={2011}
}

@INPROCEEDINGS{1624016, 
author={Jovanovic, N. and Kruegel, C. and Kirda, E.}, 
booktitle={Security and Privacy, 2006 IEEE Symposium on}, title={Pixy: a static analysis tool for detecting Web application vulnerabilities}, 
year={2006}, 
month={may}, 
volume={}, 
number={}, 
pages={6 pp. -263}, 
abstract={The number and the importance of Web applications have increased rapidly over the last years. At the same time, the quantity and impact of security vulnerabilities in such applications have grown as well. Since manual code reviews are time-consuming, error-prone and costly, the need for automated solutions has become evident. In this paper, we address the problem of vulnerable Web applications by means of static source code analysis. More precisely, we use flow-sensitive, interprocedural and context-sensitive dataflow analysis to discover vulnerable points in a program. In addition, alias and literal analysis are employed to improve the correctness and precision of the results. The presented concepts are targeted at the general class of taint-style vulnerabilities and can be applied to the detection of vulnerability types such as SQL injection, cross-site scripting, or command injection. Pixy, the open source prototype implementation of our concepts, is targeted at detecting cross-site scripting vulnerabilities in PHP scripts. Using our tool, we discovered and reported 15 previously unknown vulnerabilities in three Web applications, and reconstructed 36 known vulnerabilities in three other Web applications. The observed false positive rate is at around 50% (i.e., one false positive for each vulnerability) and therefore, low enough to permit effective security audits}, 
keywords={PHP scripts;Pixy tool;Web application;alias analysis;context-sensitive dataflow analysis;cross-site scripting vulnerabilities;flow-sensitive dataflow analysis;interprocedural dataflow analysis;literal analysis;open source prototype implementation;program vulnerability detection;static analysis tool;static source code analysis;taint-style vulnerabilities;Internet;program diagnostics;security of data;software tools;},
doi={10.1109/SP.2006.29}, 
ISSN={1081-6011},}

@misc{NVD
,	title	= {National Vulnerability Database}
,              howpublished	= {http://nvd.nist.gov/}
, key={NVD}
}

@article{
,	year	= {2012}
}

@inproceedings{Heumann10quantifyingthe
,	author	= {Thomas Heumann and Sven T\"{u}rpe and J\"{o}rg Keller}
,	title	= {Quantifying the Attack Surface of a Web Application}
,	booktitle	= {ISSE/Sicherheit 2010: Information Security Solutions Europe - Sicherheit, Schutz und Zuverl\"{a}ssigkeit.}
,	year	= {2010}
,	pages	= {305-316}
,	organization	= {Gesellschaft f\"{u}r Informatik (GI) e.V.}
,	publisher	= {Bonner K\"{o}llen Verlag}
,	series	= {Lecture Notes in Informatics (LNI)}
,	volume	= {P-170}
,	location	= {Bonn}
,	isbn	= {978-3-88579-264-2}
,	issn	= {1617-5468 }
,	language	= {English}
,	keywords	= {Web Application; Attack Surface; Black Box; Vulnerability; Measurement;
Security Metrics, Attack Surface Metric}
,	pubkey	= {TUD-CS-2010-1880}
,	research_area	= {CASED}
,	research_sub_area	= {Secure Services}
,	abstract	= {The attack surface of a system represents the exposure of application
objects to attackers and is affected primarily by architecture and design
decisions. Given otherwise consistent conditions, reducing the attack
surface of a system or an application is expected to reduce its overall
vulnerability. So far, only systems have been considered but not single
applications. As web applications provide a large set of applications built
upon a common set of concepts and technologies, we choose them as an
example, and provide qualitative and quantitative indicators. We propose a
multi-dimensional metric for the attack surface of web applications, and
discuss the rationale behind. Our metric is easy to use. It comprises both
a scalar numeric indicator for easy comparison and a more detailed vector
representation for deeper analysis. The metric can be used to guide
security testing and development. We validate the applicability and
suitability of the metric with popular web applications, of which knowledge
about their
vulnerability already exists. }
,	pdf	= {testlab.sit.fraunhofer.de/downloads/Publications/heumann-quantifying_the_attack_surface_of_a_web_application-GI_Sicherheit_2010.pdf}
}

@misc{insitutetop
,	title	= {Top Cyber Security Risks}
,	year	= {2009}
,	howpublished	= {(SANS Institute) http://www.sans.org/top-cyber-security-risks/}
,	key	= {Top Cyber Security Risks}
}

@article{Scholte2012344,
title = "Have things changed now? {A}n empirical study on input validation vulnerabilities in web applications",
journal = "Computers \& Security",
publisher = "Elsevier",
volume = "31",
number = "3",
pages = "344 - 356",
year = "2012",
note = "",
issn = "0167-4048",
doi = "10.1016/j.cose.2011.12.013",
url = "http://www.sciencedirect.com/science/article/pii/S0167404811001684",
author = "Theodoor Scholte and Davide Balzarotti and Engin Kirda",
keywords = "Security",
keywords = "Software engineering",
keywords = "Web security",
keywords = "Vulnerability study",
keywords = "Input validation",
keywords = "Web application",
abstract = "Web applications have become important services in our daily lives. Millions of users use web applications to obtain information, perform financial transactions, have fun, socialize, and communicate. Unfortunately, web applications are also frequently targeted by attackers. Recent data from SANS institute estimates that up to 60% of Internet attacks target web applications.

In this paper, we perform an empirical analysis of a large number of web vulnerability reports with the aim of understanding how input validation flaws have evolved in the last decade. In particular, we are interested in finding out if developers are more aware of web security problems today than they used to be in the past. Our results suggest that the complexity of the attacks have not changed significantly and that many web problems are still simple in nature. Hence, despite awareness programs provided by organizations such as MITRE, SANS Institute and OWASP, application developers seem to be either not aware of these classes of vulnerabilities, or unable to implement effective countermeasures. Therefore, we believe that there is a growing need for languages and application platforms that attack the root of the problem and secure applications by design."
}



@inproceedings{hutchins2011intelligence,
  title={Intelligence-Driven Computer Network Defense Informed by Analysis of Adversary Campaigns and Intrusion Kill Chains},
  author={Hutchins, E.M. and Cloppert, M. and Amin, R.},
  booktitle={Proc. 6th Int’l Conf. Information Warfare and Security},
  pages={113--125},
  year={2011}
}

@inproceedings{Brumley:2008:APE:1397759.1398066,
 author = {Brumley, David and Poosankam, Pongsin and Song, Dawn and Zheng, Jiang},
 title = {Automatic Patch-Based Exploit Generation is Possible: Techniques and Implications},
 booktitle = {Proceedings of the 2008 IEEE Symposium on Security and Privacy},
 series = {SP '08},
 year = {2008},
 isbn = {978-0-7695-3168-7},
 pages = {143--157},
 numpages = {15},
 url = {http://dx.doi.org/10.1109/SP.2008.17},
 doi = {10.1109/SP.2008.17},
 acmid = {1398066},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {exploit generation, symbolic execution, combined execution, test case generation, patch},
} 

@inproceedings{Akhawe:2010:TFF:1844769.1845417,
 author = {Akhawe, Devdatta and Barth, Adam and Lam, Peifung E. and Mitchell, John and Song, Dawn},
 title = {Towards a Formal Foundation of Web Security},
 booktitle = {Proceedings of the 2010 23rd IEEE Computer Security Foundations Symposium},
 series = {CSF '10},
 year = {2010},
 isbn = {978-0-7695-4082-5},
 pages = {290--304},
 numpages = {15},
 url = {http://dx.doi.org/10.1109/CSF.2010.27},
 doi = {10.1109/CSF.2010.27},
 acmid = {1845417},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 

@inproceedings{Ball:2003:SCL:604131.604140,
 author = {Ball, Thomas and Naik, Mayur and Rajamani, Sriram K.},
 title = {From symptom to cause: localizing errors in counterexample traces},
 booktitle = {Proceedings of the 30th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
 series = {POPL '03},
 year = {2003},
 isbn = {1-58113-628-5},
 location = {New Orleans, Louisiana, USA},
 pages = {97--105},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/604131.604140},
 doi = {10.1145/604131.604140},
 acmid = {604140},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {debugging, software model checking},
} 

@ARTICLE{6096617, 
author={Guido, D.}, 
journal={Security Privacy, IEEE}, 
title={A Case Study of Intelligence-Driven Defense}, 
year={2011}, 
month={nov.-dec. }, 
volume={9}, 
number={6}, 
pages={67 -70}, 
abstract={We can mitigate the threat of mass malware by understanding the techniques, tactics, and procedures unique to this threat. An analysis of empirical attacker data indicates that basic, generic defenses, such as minor reductions of the attack surface and the use of available platform memory protection, are effective against mass malware.}, 
keywords={attack surface;empirical attacker data analysis;intelligence-driven defense;mass malware threat;platform memory protection;invasive software;}, 
doi={10.1109/MSP.2011.158}, 
ISSN={1540-7993},}

#

@inproceedings{Weimer:2009:AFP:1555001.1555051,
 author = {Weimer, Westley and Nguyen, ThanhVu and Le Goues, Claire and Forrest, Stephanie},
 title = {Automatically finding patches using genetic programming},
 booktitle = {Proceedings of the 31st International Conference on Software Engineering},
 series = {ICSE '09},
 year = {2009},
 isbn = {978-1-4244-3453-4},
 pages = {364--374},
 numpages = {11},
 url = {http://dx.doi.org/10.1109/ICSE.2009.5070536},
 doi = {10.1109/ICSE.2009.5070536},
 acmid = {1555051},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 


@inproceedings{Chandra:2009:SPA:1542476.1542517,
 author = {Chandra, Satish and Fink, Stephen J. and Sridharan, Manu},
 title = {Snugglebug: a powerful approach to weakest preconditions},
 booktitle = {Proceedings of the 2009 ACM SIGPLAN conference on Programming language design and implementation},
 series = {PLDI '09},
 year = {2009},
 isbn = {978-1-60558-392-1},
 location = {Dublin, Ireland},
 pages = {363--374},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1542476.1542517},
 doi = {10.1145/1542476.1542517},
 acmid = {1542517},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {interprocedural analysis, symbolic analysis, weakest preconditions},
} 


@inproceedings{Xie:2006:SDS:1267336.1267349,
 author = {Xie, Yichen and Aiken, Alex},
 title = {Static detection of security vulnerabilities in scripting languages},
 booktitle = {Proceedings of the 15th conference on USENIX Security Symposium - Volume 15},
 series = {USENIX-SS'06},
 year = {2006},
 location = {Vancouver, B.C., Canada},
 articleno = {13},
 url = {http://dl.acm.org/citation.cfm?id=1267336.1267349},
 acmid = {1267349},
 publisher = {USENIX Association},
 address = {Berkeley, CA, USA},
} 


@misc{onlinepe
,	title	= {Tutorial on Online Partial Evaluation}
}

@inproceedings{Shali:2011:HPE:2048066.2048098,
 author = {Shali, Amin and Cook, William R.},
 title = {Hybrid partial evaluation},
 booktitle = {Proceedings of the 2011 ACM international conference on Object oriented programming systems languages and applications},
 series = {OOPSLA '11},
 year = {2011},
 isbn = {978-1-4503-0940-0},
 location = {Portland, Oregon, USA},
 pages = {375--390},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/2048066.2048098},
 doi = {10.1145/2048066.2048098},
 acmid = {2048098},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {hybrid, object-oriented languages, partial evaluation},
} 


@inproceedings{Ma:2011:DSE:2041552.2041563,
 author = {Ma, Kin-Keung and Phang, Khoo Yit and Foster, Jeffrey S. and Hicks, Michael},
 title = {Directed symbolic execution},
 booktitle = {Proceedings of the 18th international conference on Static analysis},
 series = {SAS'11},
 year = {2011},
 isbn = {978-3-642-23701-0},
 location = {Venice, Italy},
 pages = {95--111},
 numpages = {17},
 url = {http://dl.acm.org/citation.cfm?id=2041552.2041563},
 acmid = {2041563},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 


@ARTICLE{attacksurface
,	author	= {Manadhata, P.K. and Wing, J.M.}
,	title	= {An Attack Surface Metric}
,	journal	= {Software Engineering, IEEE Transactions on}
,	year	= {2011}
,	volume	= {37}
,	number	= {3}
,	pages	= {371 -386}
,	month	= {May-June}
,	abstract	= {Measurement of software security is a long-standing challenge to the research community. At the same time, practical security metrics and measurements are essential for secure software development. Hence, the need for metrics is more pressing now due to a growing demand for secure software. In this paper, we propose using a software system's attack surface measurement as an indicator of the system's security. We formalize the notion of a system's attack surface and introduce an attack surface metric to measure the attack surface in a systematic manner. Our measurement method is agnostic to a software system's implementation language and is applicable to systems of all sizes; we demonstrate our method by measuring the attack surfaces of small desktop applications and large enterprise systems implemented in C and Java. We conducted three exploratory empirical studies to validate our method. Software developers can mitigate their software's security risk by measuring and reducing their software's attack surfaces. Our attack surface reduction approach complements the software industry's traditional code quality improvement approach for security risk mitigation and is useful in multiple phases of the software development lifecycle. Our collaboration with SAP demonstrates the use of our metric in the software development process.}
,	keywords	= {C language;Java language;attack surface metric;implementation language;security metrics;software development;software security;C language;Java;security;software metrics;}
,	doi	= {10.1109/TSE.2010.60}
,	issn	= {0098-5589}
}

@inproceedings{Gegick:2005:MAP:1083200.1083211,
 author = {Gegick, Michael and Williams, Laurie},
 title = {Matching attack patterns to security vulnerabilities in software-intensive system designs},
 booktitle = {Proceedings of the 2005 workshop on Software engineering for secure systems\—building trustworthy applications},
 series = {SESS '05},
 year = {2005},
 isbn = {1-59593-114-7},
 location = {St. Louis, Missouri},
 pages = {1--7},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/1082983.1083211},
 doi = {10.1145/1082983.1083211},
 acmid = {1083211},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {design, regular expression, security},
} 


@incollection {springerlink:10.1007/978-3-642-04474-8_18,
   author = {Roschke, Sebastian and Cheng, Feng and Schuppenies, Robert and Meinel, Christoph},
   affiliation = {University of Potsdam Hasso Plattner Institute (HPI) P.O. Box 900460 14440 Potsdam Germany},
   title = {Towards Unifying Vulnerability Information for Attack Graph Construction},
   booktitle = {Information Security},
   series = {Lecture Notes in Computer Science},
   editor = {Samarati, Pierangela and Yung, Moti and Martinelli, Fabio and Ardagna, Claudio},
   publisher = {Springer Berlin / Heidelberg},
   isbn = {978-3-642-04473-1},
   keyword = {Computer Science},
   pages = {218-233},
   volume = {5735},
   url = {http://dx.doi.org/10.1007/978-3-642-04474-8_18},
   note = {10.1007/978-3-642-04474-8_18},
   abstract = {Attack graph is used as an effective method to model, analyze, and evaluate the security of complicated computer systems or networks. The attack graph workflow consists of three parts: information gathering, attack graph construction, and visualization. To construct an attack graph, runtime information on the target system or network environment should be monitored, gathered, and later evaluated with existing descriptions of known vulnerabilities. The output will be visualized into a graph structure for further measurements. Information gatherer, vulnerability repository, and the visualization module are three important components of an attack graph constructor. However, high quality attack graph construction relies on up-to-date vulnerability information. There are already some existing databases maintained by security companies, a community, or governments. Such databases can not be directly used for generating attack graph, due to missing unification of the provided information. This paper challenged the automatic extraction of meaningful information from various existing vulnerability databases. After comparing existing vulnerability databases, a new method is proposed for automatic extraction of vulnerability information from textual descriptions. Finally, a prototype was implemented to proof the applicability of the proposed method for attack graph construction.},
   year = {2009}
}

@INPROCEEDINGS{4725309, 
author={Fonseca, J. and Vieira, M. and Madeira, H. and Henrique, M.}, 
booktitle={Dependable Computing, 2008. PRDC '08. 14th IEEE Pacific Rim International Symposium on}, 
title={Training Security Assurance Teams Using Vulnerability Injection}, 
year={2008}, 
month={dec.}, 
volume={}, 
number={}, 
pages={297 -304}, 
abstract={Writing secure Web applications is a complex task. In fact, a vast majority of Web applications are likely to have security vulnerabilities that can be exploited using simple tools like a common Web browser. This represents a great danger as the attacks may have disastrous consequences to organizations, harming their assets and reputation. To mitigate these vulnerabilities, security code inspections and penetration tests must be conducted by well-trained teams during the development of the application. However, effective code inspections and testing takes time and cost a lot of money, even before any business revenue. Furthermore, software quality assurance teams typically lack the knowledge required to effectively detect security problems. In this paper we propose an approach to quickly and effectively train security assurance teams in the context of web application development. The approach combines a novel vulnerability injection technique with relevant guidance information about the most common security vulnerabilities to provide a realistic training scenario. Our experimental results show that a short training period is sufficient to clearly improve the ability of security assurance teams to detect vulnerabilities during both code inspections and penetration tests.}, 
keywords={Web browser;code inspections;penetration tests;software quality assurance;training security assurance teams;vulnerability injection technique;Internet;security of data;software quality;}, 
doi={10.1109/PRDC.2008.43}, 
ISSN={},}

@inproceedings{Balzarotti:2007:MVA:1315245.1315250
,	author	= {Balzarotti, Davide and Cova, Marco and Felmetsger, Viktoria V. and Vigna, Giovanni}
,	title	= {Multi-module vulnerability analysis of web-based applications}
,	booktitle	= {Proceedings of ACM CCS '07 Conference on Computer and communications security}
,	year	= {2007}
,	pages	= {25--35}
,	isbn	= {978-1-59593-703-2}
,	numpages	= {11}
,	url	= {http://doi.acm.org/10.1145/1315245.1315250}
,	doi	= {10.1145/1315245.1315250}
,	acmid	= {1315250}
,	keywords	= {dynamic analysis, multi-step attacks, static analysis, vulnerability analysis, web applications}
}

@incollection {springerlink:10.1007/0-387-25660-1_20,
   author = {Nguyen-Tuong, Anh and Guarnieri, Salvatore and Greene, Doug and Shirley, Jeff and Evans, David},
   affiliation = {University of Virginia Department of Computer Science 151 Engineer’s Way Charlottesville VA 22904-4740 USA},
   title = {Automatically Hardening Web Applications Using Precise Tainting},
   booktitle = {Security and Privacy in the Age of Ubiquitous Computing},
   series = {IFIP Advances in Information and Communication Technology},
   editor = {Sasaki, Ryoichi and Qing, Sihan and Okamoto, Eiji and Yoshiura, Hiroshi},
   publisher = {Springer Boston},
   isbn = {978-0-387-25658-0},
   keyword = {Computer Science},
   pages = {295-307},
   volume = {181},
   url = {http://dx.doi.org/10.1007/0-387-25660-1_20},
   note = {10.1007/0-387-25660-1_20},
   abstract = {Most web applications contain security vulnerabilities. The simple and natural ways of creating a web application are prone to SQL injection attacks and cross-site scripting attacks as well as other less common vulnerabilities. In response, many tools have been developed for detecting or mitigating common web application vulnerabilities. Existing techniques either require effort from the site developer or are prone to false positives. This paper presents a fully automated approach to securely hardening web applications. It is based on precisely tracking taintedness of data and checking specifically for dangerous content only in parts of commands and output that came from untrustworthy sources. Unlike previous work in which everything that is derived from tainted input is tainted, our approach precisely tracks taintedness within data values.},
   year = {2005}
}

@INPROCEEDINGS{4567017, 
author={Darmaillacq, V.}, 
booktitle={Software Testing Verification and Validation Workshop, 2008. ICSTW '08. IEEE International Conference on}, 
title={Security policy testing using vulnerability exploit chaining}, 
year={2008}, 
month={april}, 
volume={}, 
number={}, 
pages={260 -261}, 
abstract={Security policy validation based on conformance testing is a promising approach, but it lacks both of a fault model and of better test selection procedures. Penetration testing approaches rely on a fault model based on the exploitation of sequences of vulnerabilities. This document proposes a method to generate test purposes to validate the conformance of a system to a security policy using a fault model inspired from penetration testing.}, 
keywords={conformance testing;security policy testing;security policy validation;program testing;program verification;security of data;}, 
doi={10.1109/ICSTW.2008.37}, 
ISSN={},}

@article{somayajiunderstanding
,	author	= {Somayaji, A. and Neti, S. and Locasto, M.E.}
,	title	= {Understanding Attack Scalability using Vulnerability Sets}
,	journal	= {Unpublished Submission}
,	year	= {2012}
}

@INPROCEEDINGS{6032214, 
author={Petajasoja, S. and Kortti, H. and Takanen, A. and Tirila, J.}, 
booktitle={Computer Software and Applications Conference Workshops (COMPSACW), 2011 IEEE 35th Annual}, 
title={IMS Threat and Attack Surface Analysis Using Common Vulnerability Scoring System}, 
year={2011}, 
month={july}, 
volume={}, 
number={}, 
pages={68 -73}, 
abstract={For the purposes of this study, IMS specifications and public sources were analyzed using the general attack surface analysis methodology. These findings were verified and augmented by active scanning and passive analysis of the available real-world IMS test setups that were investigated during the project. As various tests and security probes were performed against the test setups, the system behaviour was analyzed for previously undetermined interactions and transient attack surfaces. After the IMS attack vectors had been identified, the Common Vulnerability Scoring System version 2 (CVSSv2) Base Scores were used to prioritize the IMS attack surface interfaces. CVSS is an industry standard for classifying vulnerabilities. It must be noted however that the idea of applying CVSS scoring to an a priori comparison of vulnerability categories and potential attack surfaces is original research by the authors of this study.}, 
keywords={IMS attack surface analysis;IMS attack surface interfaces;IMS attack vectors;IMS specifications;IMS threat;IP multimedia subsystem;active scanning;common vulnerability scoring system version 2 base scores;general attack surface analysis methodology;passive analysis;public sources;IP networks;computer network security;multimedia systems;}, 
doi={10.1109/COMPSACW.2011.22}, 
ISSN={},}

@techreport{brumley2007towards
,	author	= {Brumley, D. and Liang, Z. and Newsome, J. and Song, D.}
,	title	= {Towards Practical Automatic Generation of Multipath Vulnerability Signatures}
,	institution	= {CMU}
,	year	= {2007}
,	number	= {CMU-CS-07-150}
,	address	= {Pittsburgh, PA, USA}
}

@incollection {springerlink:10.1007/978-3-540-24679-4_182,
   author = {Tian, H. and Huang, L. and Shan, J. and Chen, G.},
   affiliation = {Department of Computer Science, University of Science and Technology of China, Hefei, Anhui, China},
   title = {Automated Vulnerability Management through Web Services},
   booktitle = {Grid and Cooperative Computing},
   series = {Lecture Notes in Computer Science},
   editor = {Li, Minglu and Sun, Xian-He and Deng, Qian-ni and Ni, Jun},
   publisher = {Springer Berlin / Heidelberg},
   isbn = {978-3-540-21988-0},
   keyword = {Computer Science},
   pages = {1067-1070},
   volume = {3032},
   url = {http://dx.doi.org/10.1007/978-3-540-24679-4_182},
   note = {10.1007/978-3-540-24679-4_182},
   abstract = {Vulnerability management plays a key role in the security area, but it is now too time-consuming, and error-prone. Based on a machine-readable vulnerability description language CVML, this paper proposes an automated vulnerability management framework through web services, which alleviates the burden of administrators and improves the security of systems dramatically.},
   year = {2004}
}

@inproceedings{Wang:2006:PVB:1180405.1180412,
 author = {Wang, XiaoFeng and Li, Zhuowei and Xu, Jun and Reiter, Michael K. and Kil, Chongkyung and Choi, Jong Youl},
 title = {Packet vaccine: black-box exploit detection and signature generation},
 booktitle = {Proceedings of the 13th ACM conference on Computer and communications security},
 series = {CCS '06},
 year = {2006},
 isbn = {1-59593-518-5},
 location = {Alexandria, Virginia, USA},
 pages = {37--46},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1180405.1180412},
 doi = {10.1145/1180405.1180412},
 acmid = {1180412},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {black-box defense, exploit detection, signature generation, vaccine injection, worm},
} 

@ARTICLE{automaticvulsig
,	author	= {Brumley, D. and Newsome, J. and Song, D. and Hao Wang and Jha, S.}
,	title	= {Theory and Techniques for Automatic Generation of Vulnerability-Based Signatures}
,	journal	= {Dependable and Secure Computing, IEEE Transactions on}
,	year	= {2008}
,	volume	= {5}
,	number	= {4}
,	pages	= {224 -241}
,	month	= {oct.-dec. }
,	abstract	= {In this paper, we explore the problem of creating emphvulnerability signatures. A vulnerability signature is based on a program vulnerability, and is not specific to any particular exploit. The advantage of vulnerability signatures is that their quality can be guaranteed. In particular, we create vulnerability signatures which are guaranteed to have zero false positives. We show how to automate signature creation for any vulnerability that can be detected by a runtime monitor. We provide a formal definition of a vulnerability signature, and investigate the computational complexity of creating and matching vulnerability signatures. We systematically explore the design space of vulnerability signatures. We also provide specific techniques for creating vulnerability signatures in a variety of language classes. In order to demonstrate our techniques, we have built a prototype system. Our experiments show that we can, using a single exploit, automatically generate a vulnerability signature as a regular expression, as a small program, or as a system of constraints. We demonstrate techniques for creating signatures of vulnerabilities which can be exploited via multiple program paths. Our results indicate that our approach is a viable option for signature generation, especially when guarantees are desired.}
,	keywords	= {Turing-complete language;automated generation;multiple vulnerable program paths;multiple-path vulnerability;program vulnerability;vulnerability-based signatures;Turing machines;computational complexity;digital signatures;}
,	doi	= {10.1109/TDSC.2008.55}
,	issn	= {1545-5971}
}

@INPROCEEDINGS{5070521, 
author={Kieyzun, A. and Guo, P.J. and Jayaraman, K. and Ernst, M.D.}, 
booktitle={Software Engineering, 2009. ICSE 2009. IEEE 31st International Conference on}, 
title={Automatic creation of SQL Injection and cross-site scripting attacks}, 
year={2009}, 
month={may}, 
volume={}, 
number={}, 
pages={199 -209}, 
abstract={We present a technique for finding security vulnerabilities in Web applications. SQL injection (SQLI) and cross-site scripting (XSS) attacks are widespread forms of attack in which the attacker crafts the input to the application to access or modify user data and execute malicious code. In the most serious attacks (called second-order, or persistent, XSS), an attacker can corrupt a database so as to cause subsequent users to execute malicious code. This paper presents an automatic technique for creating inputs that expose SQLI and XSS vulnerabilities. The technique generates sample inputs, symbolically tracks taints through execution (including through database accesses), and mutates the inputs to produce concrete exploits. Ours is the first analysis of which we are aware that precisely addresses second-order XSS attacks. Our technique creates real attack vectors, has few false positives, incurs no runtime overhead for the deployed application, works without requiring modification of application code, and handles dynamic programming-language constructs. We implemented the technique for PHP, in a tool ARDILLA. We evaluated ARDILLA on five PHP applications and found 68 previously unknown vulnerabilities (23 SQLI, 33 first-order XSS, and 12 second-order XSS).}, 
keywords={SQL injection;Web applications;cross-site scripting attacks;malicious code;security vulnerabilities;Internet;SQL;security of data;}, 
doi={10.1109/ICSE.2009.5070521}, 
ISSN={0270-5257},}

@inproceedings{Sommers:2004:FMW:1028788.1028799,
 author = {Sommers, Joel and Yegneswaran, Vinod and Barford, Paul},
 title = {A framework for malicious workload generation},
 booktitle = {Proceedings of the 4th ACM SIGCOMM conference on Internet measurement},
 series = {IMC '04},
 year = {2004},
 isbn = {1-58113-821-0},
 location = {Taormina, Sicily, Italy},
 pages = {82--87},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/1028788.1028799},
 doi = {10.1145/1028788.1028799},
 acmid = {1028799},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {network intrusions, traffic generation},
} 

@ARTICLE{1556535, 
author={Sidiroglou, S. and Keromytis, A.D.}, 
journal={Security Privacy, IEEE}, 
title={Countering network worms through automatic patch generation}, 
year={2005}, 
month={nov.-dec.}, 
volume={3}, 
number={6}, 
pages={ 41 - 49}, 
abstract={ To counter zero-day worms that exploit software flaws such as buffer overflows, this end-point architecture uses source code transformations to automatically create and test software patches for vulnerable segments of targeted applications.}, 
keywords={ automatic patch generation; buffer overflow; end-point architecture; network worm; software flaws; source code transformation; buffer storage; invasive software; source coding; telecommunication security;}, 
doi={10.1109/MSP.2005.144}, 
ISSN={1540-7993},}

@ARTICLE{5374427, 
author={Antunes, J. and Neves, N. and Correia, M. and Verissimo, P. and Neves, R.}, 
journal={Software Engineering, IEEE Transactions on}, 
title={Vulnerability Discovery with Attack Injection}, 
year={2010}, 
month={may-june }, 
volume={36}, 
number={3}, 
pages={357 -370}, 
abstract={The increasing reliance put on networked computer systems demands higher levels of dependability. This is even more relevant as new threats and forms of attack are constantly being revealed, compromising the security of systems. This paper addresses this problem by presenting an attack injection methodology for the automatic discovery of vulnerabilities in software components. The proposed methodology, implemented in AJECT, follows an approach similar to hackers and security analysts to discover vulnerabilities in network-connected servers. AJECT uses a specification of the server's communication protocol and predefined test case generation algorithms to automatically create a large number of attacks. Then, while it injects these attacks through the network, it monitors the execution of the server in the target system and the responses returned to the clients. The observation of an unexpected behavior suggests the presence of a vulnerability that was triggered by some particular attack (or group of attacks). This attack can then be used to reproduce the anomaly and to assist the removal of the error. To assess the usefulness of this approach, several attack injection campaigns were performed with 16 publicly available POP and IMAP servers. The results show that AJECT could effectively be used to locate vulnerabilities, even on well-known servers tested throughout the years.}, 
keywords={AJECT;IMAP servers;POP servers;attack injection;hackers analysts;networked computer systems;security analysts;software components;vulnerability discovery;computer crime;software engineering;}, 
doi={10.1109/TSE.2009.91}, 
ISSN={0098-5589},}

@INPROCEEDINGS{1633534, 
author={Neves, N. and Antunes, J. and Correia, M. and Verissimo, P. and Neves, R.}, 
booktitle={Dependable Systems and Networks, 2006. DSN 2006. International Conference on}, 
title={Using Attack Injection to Discover New Vulnerabilities}, 
year={2006}, 
month={june}, 
volume={}, 
number={}, 
pages={457 -466}, 
abstract={Due to our increasing reliance on computer systems, security incidents and their causes are important problems that need to be addressed. To contribute to this objective, the paper describes a new tool for the discovery of security vulnerabilities on network connected servers. The AJECT tool uses a specification of the server's communication protocol to automatically generate a large number of attacks accordingly to some predefined test classes. Then, while it performs these attacks through the network, it monitors the behavior of the server both from a client perspective and inside the target machine. The observation of an incorrect behavior indicates a successful attack and the potential existence of a vulnerability. To demonstrate the usefulness of this approach, a considerable number of experiments were carried out with several IMAP servers. The results show that AJECT can discover several kinds of vulnerabilities, including a previously unknown vulnerability}, 
keywords={AJECT tool;attack injection;network connected servers;security vulnerability discovery;server communication protocol;client-server systems;computer network reliability;telecommunication security;transport protocols;}, 
doi={10.1109/DSN.2006.72}, 
ISSN={},}

@INPROCEEDINGS{1623999, 
author={Zhichun Li and Manan Sanghi and Yan Chen and Ming-Yang Kao and Chavez, B.}, 
booktitle={Security and Privacy, 2006 IEEE Symposium on}, 
title={Hamsa: fast signature generation for zero-day polymorphic worms with provable attack resilience}, 
year={2006}, 
month={may}, 
volume={}, 
number={}, 
pages={15 pp. -47}, 
abstract={Zero-day polymorphic worms pose a serious threat to the security of Internet infrastructures. Given their rapid propagation, it is crucial to detect them at edge networks and automatically generate signatures in the early stages of infection. Most existing approaches for automatic signature generation need host information and are thus not applicable for deployment on high-speed network links. In this paper, we propose Hamsa, a network-based automated signature generation system for polymorphic worms which is fast, noise-tolerant and attack-resilient. Essentially, we propose a realistic model to analyze the invariant content of polymorphic worms which allows us to make analytical attack-resilience guarantees for the signature generation algorithm. Evaluation based on a range of polymorphic worms and polymorphic engines demonstrates that Hamsa significantly outperforms Polygraph (J. Newsome et al., 2005) in terms of efficiency, accuracy, and attack resilience}, 
keywords={Hamsa;Internet infrastructure security;analytical attack-resilience guarantees;attack resilience;automatic signature generation;fast signature generation;high-speed network links;network-based automated signature generation system;polymorphic engines;zero-day polymorphic worms;Internet;invasive software;telecommunication security;}, 
doi={10.1109/SP.2006.18}, 
ISSN={1081-6011},}

@incollection {springerlink:10.1007/978-3-540-70567-3_22,
   author = {Wang, Lingyu and Islam, Tania and Long, Tao and Singhal, Anoop and Jajodia, Sushil},
   affiliation = {Concordia University Concordia Institute for Information Systems Engineering Montreal QC H3G 1M8 Canada},
   title = {An Attack Graph-Based Probabilistic Security Metric},
   booktitle = {Data and Applications Security XXII},
   series = {Lecture Notes in Computer Science},
   editor = {Atluri, Vijay},
   publisher = {Springer Berlin / Heidelberg},
   isbn = {978-3-540-70566-6},
   keyword = {Computer Science},
   pages = {283-296},
   volume = {5094},
   url = {http://dx.doi.org/10.1007/978-3-540-70567-3_22},
   note = {10.1007/978-3-540-70567-3_22},
   abstract = {To protect critical resources in today’s networked environments, it is desirable to quantify the likelihood of potential multi-step attacks that combine multiple vulnerabilities. This now becomes feasible due to a model of causal relationships between vulnerabilities, namely, attack graph. This paper proposes an attack graph-based probabilistic metric for network security and studies its efficient computation. We first define the basic metric and provide an intuitive and meaningful interpretation to the metric. We then study the definition in more complex attack graphs with cycles and extend the definition accordingly. We show that computing the metric directly from its definition is not efficient in many cases and propose heuristics to improve the efficiency of such computation.},
   year = {2008}
}

@inproceedings{Wang:2007:TMN:1314257.1314273,
 author = {Wang, Lingyu and Singhal, Anoop and Jajodia, Sushil},
 title = {Toward measuring network security using attack graphs},
 booktitle = {Proceedings of the 2007 ACM workshop on Quality of protection},
 series = {QoP '07},
 year = {2007},
 isbn = {978-1-59593-885-5},
 location = {Alexandria, Virginia, USA},
 pages = {49--54},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/1314257.1314273},
 doi = {10.1145/1314257.1314273},
 acmid = {1314273},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {attack graphs, intrusion detection, security metrics, vulnerability analysis},
} 

@INPROCEEDINGS{4568517, 
author={Malhotra, S. and Bhattacharya, S. and Ghosh, S.K.}, 
booktitle={Computer and Information Technology Workshops, 2008. CIT Workshops 2008. IEEE 8th International Conference on}, 
title={A Vulnerability and Exploit Independent Approach for Attack Path Prediction}, 
year={2008}, 
month={july}, 
volume={}, 
number={}, 
pages={282 -287}, 
abstract={Network Security has gained an ever increasing importance today because of the increased dependence on the networks. One way to assess the threats to the networks is through the use of the attack graphs. However, because of their sheer enormity and complexity the analysis becomes difficult. Given an attack graph the identification of a probable attack path still remains an issue. This paper presents an attack path identification methodology which is both efficient and scalable. The proposed approach is based on the attack surface measure of the individual hosts comprising the network and the access levels between them and it identifies the attack path independent of the vulnerabilities or the exploits that may exist.}, 
keywords={attack graphs;attack path prediction;exploit independent approach;network security;vulnerability;computer networks;graph theory;security of data;}, 
doi={10.1109/CIT.2008.Workshops.73}, 
ISSN={},}

@INPROCEEDINGS{1004377, 
author={Sheyner, O. and Haines, J. and Jha, S. and Lippmann, R. and Wing, J.M.}, 
booktitle={Security and Privacy, 2002. Proceedings. 2002 IEEE Symposium on}, 
title={Automated generation and analysis of attack graphs}, 
year={2002}, 
month={}, 
volume={}, 
number={}, 
pages={ 273 - 284}, 
abstract={ An integral part of modeling the global view of network security is constructing attack graphs. Manual attack graph construction is tedious, error-prone, and impractical for attack graphs larger than a hundred nodes. In this paper we present an automated technique for generating and analyzing attack graphs. We base our technique on symbolic model checking algorithms, letting us construct attack graphs automatically and efficiently. We also describe two analyses to help decide which attacks would be most cost-effective to guard against. We implemented our technique in a tool suite and tested it on a small network example, which includes models of a firewall and an intrusion detection system.}, 
keywords={ automated attack graph analysis; automated attack graph generation; firewall; intrusion detection system; network security; symbolic model checking algorithms; authorisation; computer network management; telecommunication security;}, 
doi={10.1109/SECPRI.2002.1004377}, 
ISSN={1081-6011 },}

@INPROCEEDINGS{1623997, 
author={Brumley, D. and Newsome, J. and Song, D. and Hao Wang and Somesh Jha}, 
booktitle={Security and Privacy, 2006 IEEE Symposium on}, 
title={Towards automatic generation of vulnerability-based signatures}, 
year={2006}, 
month={may}, 
volume={}, 
number={}, 
pages={15 pp. -16}, 
abstract={In this paper we explore the problem of creating vulnerability signatures. A vulnerability signature matches all exploits of a given vulnerability, even polymorphic or metamorphic variants. Our work departs from previous approaches by focusing on the semantics of the program and vulnerability exercised by a sample exploit instead of the semantics or syntax of the exploit itself. We show the semantics of a vulnerability define a language which contains all and only those inputs that exploit the vulnerability. A vulnerability signature is a representation (e.g., a regular expression) of the vulnerability language. Unlike exploit-based signatures whose error rate can only be empirically measured for known test cases, the quality of a vulnerability signature can be formally quantified for all possible inputs. We provide a formal definition of a vulnerability signature and investigate the computational complexity of creating and matching vulnerability signatures. We also systematically explore the design space of vulnerability signatures. We identify three central issues in vulnerability-signature creation: how a vulnerability signature represents the set of inputs that may exercise a vulnerability, the vulnerability coverage (i.e., number of vulnerable program paths) that is subject to our analysis during signature creation, and how a vulnerability signature is then created for a given representation and coverage. We propose new data-flow analysis and novel adoption of existing techniques such as constraint solving for automatically generating vulnerability signatures. We have built a prototype system to test our techniques. Our experiments show that we can automatically generate a vulnerability signature using a single exploit which is of much higher quality than previous exploit-based signatures. In addition, our techniques have several other security applications, and thus may be of independent interest}, 
keywords={computational complexity;constraint solving;data-flow analysis;formal definition;program semantics;security applications;vulnerability language;vulnerability signature;vulnerability-based signature automatic generation;formal specification;security of data;}, 
doi={10.1109/SP.2006.41}, 
ISSN={1081-6011},}

@ARTICLE{1281240, 
author={Jiwnani, K. and Zelkowitz, M.}, 
journal={Security Privacy, IEEE}, 
title={Susceptibility matrix: a new aid to software auditing}, 
year={2004}, 
month={mar-apr}, 
volume={2}, 
number={2}, 
pages={ 16 - 21}, 
abstract={ Testing for security is lengthy, complex, and costly, so focusing test efforts in areas that have the greatest number of security vulnerabilities is essential. This article describes a taxonomy-based approach that gives an insight into the distribution of vulnerabilities in a system.}, 
keywords={ security testing; security vulnerabilities; software auditing; susceptibility matrix; taxonomy-based approach; auditing; program testing; security of data;}, 
doi={10.1109/MSECP.2004.1281240}, 
ISSN={1540-7993},}

@inproceedings{mops
,	author	= {Chen, Hao and Wagner, David}
,	title	= {MOPS: an infrastructure for examining security properties of software}
,	booktitle	= {Proceedings of the 9th ACM conference on Computer and communications security}
,	year	= {2002}
,	pages	= {235--244}
,	publisher	= {ACM}
,	address	= {New York, NY, USA}
,	series	= {CCS '02}
,	isbn	= {1-58113-612-9}
,	location	= {Washington, DC, USA}
,	numpages	= {10}
,	url	= {http://doi.acm.org/10.1145/586110.586142}
,	doi	= {10.1145/586110.586142}
,	acmid	= {586142}
,	keywords	= {model checking, security, static analysis, verification}
}

@INPROCEEDINGS{4412995, 
author={Josang, A. and AlFayyadh, B. and Grandison, T. and AlZomai, M. and McNamara, J.}, 
booktitle={Computer Security Applications Conference, 2007. ACSAC 2007. Twenty-Third Annual}, 
title={Security Usability Principles for Vulnerability Analysis and Risk Assessment}, 
year={2007}, 
month={dec.}, 
volume={}, 
number={}, 
pages={269 -278}, 
abstract={Usability is the weakest link in the security chain of many prominent applications. A set of security usability principles should therefore be considered when designing and engineering IT security solutions. When improving the usability of existing security applications, it is necessary to examine the underlying security technologies used to build them, and consider whether they need to be replaced by totally new security technologies that provide a better basis for good usability. This paper examines a set of security usability principles, proposes how they can be incorporated into the risk management process, and discusses the benefits of applying these principles and process to existing and future security solutions.}, 
keywords={IT security solution;risk assessment;risk management process;security usability principle;vulnerability analysis;risk management;security of data;}, 
doi={10.1109/ACSAC.2007.14}, 
ISSN={1063-9527},}

@ARTICLE{976940, 
author={Evans, D. and Larochelle, D.}, 
journal={Software, IEEE}, 
title={Improving security using extensible lightweight static analysis}, 
year={2002}, 
month={jan/feb}, 
volume={19}, 
number={1}, 
pages={42 -51}, 
abstract={Most security attacks exploit instances of well-known classes of implementation flaws. Developers could detect and eliminate many of these flaws before deploying the software, yet these problems persist with disturbing frequency-not because the security community doesn't sufficiently understand them but because techniques for preventing them have not been integrated into the software development process. This article describes an extensible tool that uses lightweight static analysis to detect common security vulnerabilities (including buffer overflows and format string vulnerabilities)}, 
keywords={buffer overflows;extensible lightweight static analysis;format string vulnerabilities;security attacks;software development;program diagnostics;security of data;software engineering;}, 
doi={10.1109/52.976940}, 
ISSN={0740-7459},}

@article{vuldiscovery
,	author	= {Ozment, Andy}
,	title	= {Vulnerability discovery \& software security}
,	journal	= {University of Cambridge Computer Laboratory Computer Security Group \&Magdalene College}
,	year	= {2007}
,	publisher	= {Citeseer}
}

@article{QIQQA-FKWKI
,	author	= {~ converted by Web2PDFCOnvert.c0m}
,	title	= {}
,	year	= {}
,	publisher	= {}
}

@INPROCEEDINGS{differentialslicing
,	author	= {Johnson, N.M. and Caballero, J. and Chen, K.Z. and McCamant, S. and Poosankam, P. and Reynaud, D. and Song, D.}
,	title	= {Differential Slicing: Identifying Causal Execution Differences for Security Applications}
,	booktitle	= {Security and Privacy (SP), 2011 IEEE Symposium on}
,	year	= {2011}
,	pages	= {347 -362}
,	month	= {may}
,	abstract	= {A security analyst often needs to understand two runs of the same program that exhibit a difference in program state or output. This is important, for example, for vulnerability analysis, as well as for analyzing a malware program that features different behaviors when run in different environments. In this paper we propose a differential slicing approach that automates the analysis of such execution differences. Differential slicing outputs a causal difference graph that captures the input differences that triggered the observed difference and the causal path of differences that led from those input differences to the observed difference. The analyst uses the graph to quickly understand the observed difference. We implement differential slicing and evaluate it on the analysis of 11 real-world vulnerabilities and 2 malware samples with environment-dependent behaviors. We also evaluate it in an informal user study with two vulnerability analysts. Our results show that differential slicing successfully identifies the input differences that caused the observed difference and that the causal difference graph significantly reduces the amount of time and effort required for an analyst to understand the observed difference.}
,	keywords	= {causal difference graph;causal execution differences;differential slicing;malware program;program slicing;security of data;}
,	doi	= {10.1109/SP.2011.41}
,	issn	= {1081-6011}
}

@inproceedings{Jones:2002:VTI:581339.581397,
 author = {Jones, James A. and Harrold, Mary Jean and Stasko, John},
 title = {Visualization of test information to assist fault localization},
 booktitle = {Proceedings of the 24th International Conference on Software Engineering},
 series = {ICSE '02},
 year = {2002},
 isbn = {1-58113-472-X},
 location = {Orlando, Florida},
 pages = {467--477},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/581339.581397},
 doi = {10.1145/581339.581397},
 acmid = {581397},
 publisher = {ACM},
 address = {New York, NY, USA},
} 


@inproceedings{tarantula
,	author	= {Jones, James A. and Harrold, Mary Jean}
,	title	= {Empirical evaluation of the tarantula automatic fault-localization technique}
,	booktitle	= {Proceedings of the 20th IEEE/ACM international Conference on Automated software engineering}
,	year	= {2005}
,	pages	= {273--282}
,	publisher	= {ACM}
,	address	= {New York, NY, USA}
,	series	= {ASE '05}
,	isbn	= {1-58113-993-4}
,	location	= {Long Beach, CA, USA}
,	numpages	= {10}
,	url	= {http://doi.acm.org/10.1145/1101908.1101949}
,	doi	= {10.1145/1101908.1101949}
,	acmid	= {1101949}
,	keywords	= {automated debugging, empirical study, fault localization, program analysis}
}

@INPROCEEDINGS{497652, 
author={Agrawal, H. and Horgan, J.R. and London, S. and Wong, W.E.}, 
booktitle={Software Reliability Engineering, 1995. Proceedings., Sixth International Symposium on}, 
title={Fault localization using execution slices and dataflow tests}, 
year={1995}, 
month={oct}, 
volume={}, 
number={}, 
pages={143 -151}, 
abstract={Finding a fault in a program is a complex process which involves understanding the program's purpose, structure, semantics, and the relevant characteristics of failure producing tests. We describe a tool which supports execution slicing and dicing based on test cases. We report the results of an experiment that uses heuristic techniques in fault localization}, 
keywords={dataflow tests;execution dicing;execution slices;execution slicing;heuristic techniques;program fault localization;program purpose;program semantics;program structure;program testing;program understanding;software tool;test cases;data flow analysis;program debugging;program testing;reverse engineering;software reliability;software tools;}, 
doi={10.1109/ISSRE.1995.497652}, 
ISSN={},}

@INPROCEEDINGS{1357803, 
author={Raghavan, S. and Rohana, R. and Leon, D. and Podgurski, A. and Augustine, V.}, 
booktitle={Software Maintenance, 2004. Proceedings. 20th IEEE International Conference on}, 
title={Dex: a semantic-graph differencing tool for studying changes in large code bases}, 
year={2004}, 
month={sept.}, 
volume={}, 
number={}, 
pages={ 188 - 197}, 
abstract={ This paper describes an automated tool called Dex (difference extractor) for analyzing syntactic and semantic changes in large C-language code bases. It is applied to patches obtained from a source code repository, each of which comprises the code changes made to accomplish a particular task. Dex produces summary statistics characterizing these changes for all of the patches that are analyzed. Dex applies a graph differencing algorithm to abstract semantic graphs (ASGs) representing each version. The differences are then analyzed to identify higher-level program changes. We describe the design of Dex, its potential applications, and the results of applying it to analyze bug fixes from the Apache and GCC projects. The results include detailed information about the nature and frequency of missing condition defects in these projects.}, 
keywords={ Apache; GCC; abstract semantic graphs; automated tool; difference extractor; higher-level program changes; large C-language code bases; semantic-graph differencing tool; source code repository; C language; program debugging; software tools;}, 
doi={10.1109/ICSM.2004.1357803}, 
ISSN={1063-6773},}

@incollection {springerlink:10.1007/978-3-540-30480-7_20,
   author = {Ran, Lihua and Dyreson, Curtis and Andrews, Anneliese},
   affiliation = {School of Electrical Engineering and Computer Science, Washington State University, USA},
   title = {AutoDBT: A Framework for Automatic Testing of Web Database Applications},
   booktitle = {Web Information Systems – WISE 2004},
   series = {Lecture Notes in Computer Science},
   editor = {Zhou, Xiaofang and Su, Stanley and Papazoglou, Mike and Orlowska, Maria and Jeffery, Keith},
   publisher = {Springer Berlin / Heidelberg},
   isbn = {978-3-540-23894-2},
   keyword = {Computer Science},
   pages = {181-192},
   volume = {3306},
   url = {http://dx.doi.org/10.1007/978-3-540-30480-7_20},
   note = {10.1007/978-3-540-30480-7_20},
   abstract = {The complex functionalities and high demands of software quality make manual testing of a web application ineffective. Automatic software testing methods can help to determine if a web application is working correctly, but existing methods are unable to test whether such an application interacts correctly with a back-end database. This paper elaborates an approach, called the Automatic Database Tester (AutoDBT), that extends the functional or black-box testing of a web database application to include database updates. AutoDBT takes as input a model of the application and a set of test criteria. The model consists of a state transition diagram showing how a user navigates among pages in the application, and a data specification which captures how data flows in the application and how the database is updated. AutoDBT uses the model along with the test criteria to generate test cases for functional testing of the application.},
   year = {2004}
}

@inproceedings{Buehrer:2005:UPT:1108473.1108496,
 author = {Buehrer, Gregory and Weide, Bruce W. and Sivilotti, Paolo A. G.},
 title = {Using parse tree validation to prevent SQL injection attacks},
 booktitle = {Proceedings of the 5th international workshop on Software engineering and middleware},
 series = {SEM '05},
 year = {2005},
 isbn = {1-59593-205-4},
 location = {Lisbon, Portugal},
 pages = {106--113},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1108473.1108496},
 doi = {10.1145/1108473.1108496},
 acmid = {1108496},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@INPROCEEDINGS{1579135, 
author={Chan, W.K. and Cheung, S.C. and Tse, T.H.}, 
booktitle={Quality Software, 2005. (QSIC 2005). Fifth International Conference on}, 
title={Fault-based testing of database application programs with conceptual data model}, 
year={2005}, 
month={sept.}, 
volume={}, 
number={}, 
pages={ 187 - 196}, 
abstract={ Database application programs typically contain program units that use SQL statements to manipulate records in database instances. Testing the correctness of data manipulation by these programs is challenging. When a tester provides a database instance to test such a program, the program unit may output faulty SQL statements and, hence, manipulate inappropriate database records. Nonetheless, these failures may only be revealed in very specific database instances. This paper proposes to integrate SQL statements and the conceptual data models of an application for fault-based testing. It proposes a set of mutation operators based on the standard types of constraint used in the enhanced entity-relationship model. These operators are semantic in nature. This semantic information guides the construction of affected attributes and join conditions of mutants. The usefulness of our proposal is illustrated by an example in which a missing-record fault is revealed.}, 
keywords={ SQL statement; conceptual data model; data manipulation; database application program; database instances; database record; entity-relationship model; fault-based testing; SQL; entity-relationship modelling; program testing;}, 
doi={10.1109/QSIC.2005.27}, 
ISSN={1550-6002 },}

@article{Cohen:2006:TAC:1218776.1218785,
 author = {Cohen, Myra B. and Snyder, Joshua and Rothermel, Gregg},
 title = {Testing across configurations: implications for combinatorial testing},
 journal = {SIGSOFT Softw. Eng. Notes},
 issue_date = {November 2006},
 volume = {31},
 number = {6},
 month = nov,
 year = {2006},
 issn = {0163-5948},
 pages = {1--9},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/1218776.1218785},
 doi = {10.1145/1218776.1218785},
 acmid = {1218785},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {code coverage, combinatorial interaction testing, configurable software, empirical study},
} 


@inproceedings{du1998vulnerability,
  title={Vulnerability testing of software system using fault injection},
  author={Du, W. and Mathur, A.P.},
  booktitle={Proceeding of the International Conference on Dependable Systems and Networks (DSN 2000), Workshop On Dependability Versus Malicious Faults},
  year={1998}
}

@INPROCEEDINGS{5438043, 
author={Huning Dai and Murphy, C. and Kaiser, G.}, 
booktitle={Availability, Reliability, and Security, 2010. ARES '10 International Conference on}, 
title={Configuration Fuzzing for Software Vulnerability Detection}, 
year={2010}, 
month={feb.}, 
volume={}, 
number={}, 
pages={525 -530}, 
abstract={Many software security vulnerabilities only reveal themselves under certain conditions, i.e., particular configurations of the software together with its particular run-time environment. One approach to detecting these vulnerabilities is fuzz testing, which feeds a range of randomly modified inputs to a software application while monitoring it for failures. However, typical fuzz testing makes no guarantees regarding the syntactic and semantic validity of the input, or of how much of the input space will be explored. To address these problems, in this paper we present a new testing methodology called configuration fuzzing. Configuration fuzzing is a technique whereby the configuration of the running application is randomly modified at certain execution points, in order to check for vulnerabilities that only arise in certain conditions. As the application runs in the deployment environment, this testing technique continuously fuzzes the configuration and checks "security invariants" that, if violated, indicate a vulnerability; however, the fuzzing is performed in a duplicated copy of the original process, so that it does not affect the state of the running application. In addition to discussing the approach and describing a prototype framework for implementation, we also present the results of a case study to demonstrate the approach's efficiency.}, 
keywords={configuration fuzzing;fuzz testing;security invariants;semantic validity;software security vulnerabilities;software vulnerability detection;syntactic validity;program testing;security of data;}, 
doi={10.1109/ARES.2010.22}, 
ISSN={},}

@INPROCEEDINGS{4639338, 
author={Post, H. and Sinz, C.}, 
booktitle={Automated Software Engineering, 2008. ASE 2008. 23rd IEEE/ACM International Conference on}, 
title={Configuration Lifting: Verification meets Software Configuration}, 
year={2008}, 
month={sept.}, 
volume={}, 
number={}, 
pages={347 -350}, 
abstract={Configurable software is ubiquitous, and the term software product line (SPL) has been coined for it lately. It remains a challenge, however, how such software can be verified over all variants. Enumerating all variants and analyzing them individually is inefficient, as knowledge cannot be shared between analysis runs. Instead of enumeration we present a new technique called lifting that converts all variants into a meta-program, and thus facilitates the configuration-aware application of verification techniques like static analysis, model checking and deduction-based approaches. As a side-effect, lifting provides a technique for checking software feature models, which describe software variants, for consistency. We demonstrate the feasibility of our approach by checking configuration dependent hazards for the highly configurable Linux kernel which possesses several thousand of configurable features. Using our techniques, two novel bugs in the kernel configuration system were found.}, 
keywords={SPL;configurable Linux kernel;configuration lifting;deduction-based approaches;meta-program;model checking;software configuration;software product line;static analysis;verification techniques;Linux;configuration management;operating system kernels;product development;program verification;software reusability;}, 
doi={10.1109/ASE.2008.45}, 
ISSN={1527-1366},}

@INPROCEEDINGS{5315969, 
author={Vache, G.}, 
booktitle={Empirical Software Engineering and Measurement, 2009. ESEM 2009. 3rd International Symposium on}, 
title={Vulnerability analysis for a quantitative security evaluation}, 
year={2009}, 
month={oct.}, 
volume={}, 
number={}, 
pages={526 -534}, 
abstract={This paper presents the quantitative characterization of vulnerability life cycle and of exploit creation by probability distributions. This work aims at helping the production of quantitative measures of information system security considering system environment. In this paper, we focus on two environmental factors: the vulnerability life cycle; and the attacker behaviour. We look for the probability distributions and their parameters that could model quantatively these environmental factor events. Thus, to obtain precise measures, it is needed to characterize these events using real data. For that purpose, we first selected an appropriate vulnerability database by comparing the existing and available ones. We choose the open source vulnerability database. After having brought back the data we need, we evaluate quantitatively the model parameters related to the vulnerability life cycle and the attacker behaviour. In doing so, we look for specificities of vulnerability categories to define the parameterization of our quantitative security evaluation modelling more precisely.}, 
keywords={attacker behaviour;information system security;open source vulnerability database;probability distribution;quantitative security evaluation modelling;system environment;vulnerability database;vulnerability life cycle quantitative characterization;information systems;security of data;}, 
doi={10.1109/ESEM.2009.5315969}, 
ISSN={1938-6451},}

@inproceedings{Cui:2007:SAD:1263552.1264212,
 author = {Cui, Weidong and Peinado, Marcus and Wang, Helen J. and Locasto, Michael E.},
 title = {ShieldGen: Automatic Data Patch Generation for Unknown Vulnerabilities with Informed Probing},
 booktitle = {Proceedings of the 2007 IEEE Symposium on Security and Privacy},
 series = {SP '07},
 year = {2007},
 isbn = {0-7695-2848-1},
 pages = {252--266},
 numpages = {15},
 url = {http://dx.doi.org/10.1109/SP.2007.34},
 doi = {10.1109/SP.2007.34},
 acmid = {1264212},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 

#

#

#

#

@article{godefroid2012sage,
  title={Sage: Whitebox fuzzing for security testing},
  author={Godefroid, Patrice and Levin, Michael Y and Molnar, David},
  journal={Queue},
  volume={10},
  number={1},
  pages={20},
  year={2012},
  publisher={ACM}
}

#

#

#

#

#

#

#

@inproceedings{song2012itree,
  title={iTree: efficiently discovering high-coverage configurations using interaction trees},
  author={Song, Charles and Porter, Adam and Foster, Jeffrey S},
  booktitle={Proceedings of the 2012 International Conference on Software Engineering},
  pages={903--913},
  year={2012},
  organization={IEEE Press}
}

@misc{exploitdb
,	title	= {Exploit DB}
,	howpublished	= {http://www.exploit-db.com/}
}

@misc{w3af
,	title	= {w3af}
,	howpublished	= {http://w3af.org/}
}

@misc{metasploit,
author = {Rapid7},
title = {MetaSploit Framework},
month = Spring,
year = {2013},
howpublished ="\url{http://www.metasploit.com/}"
}

@misc{OSVDB
,	title	= {{OSVDB}: The Open Source Vulnerability Database}
,	howpublished	= {http://www.osvdb.org/}
, key = {OSVDB}

}

@misc{
,	title	= {CVE}
}

#

@techreport{lippmann2005annotated,
  title={An annotated review of past papers on attack graphs},
  author={Lippmann, Richard Paul and Ingols, Kyle William},
  year={2005},
  institution={DTIC Document}
}

@misc{injector
,	title	= {inj3ct0r}
,	howpublished	= {http://1337day.com/}
}

@misc{
,	title	= {PREDICT}
}

#

@inproceedings{senseofself
,	author	= {Forrest, Stephanie and Hofmeyr, Steven A and Somayaji, Anil and Longstaff, Thomas A}
,	title	= {A sense of self for unix processes}
,	booktitle	= {Security and Privacy, 1996. Proceedings., 1996 IEEE Symposium on}
,	year	= {1996}
,	pages	= {120--128}
,	organization	= {IEEE}
}

#

@inproceedings{layman2008mining,
  title={Mining software effort data: preliminary analysis of visual studio team system data},
  author={Layman, L. and Nagappan, N. and Guckenheimer, S. and Beehler, J. and Begel, A.},
  booktitle={Proceedings of the 2008 international working conference on Mining software repositories},
  pages={43--46},
  year={2008},
  organization={ACM}
}

@INPROCEEDINGS{1209971, 
author={ Singh, S. and Cukier, M. and Sanders, W.H.}, 
booktitle={Dependable Systems and Networks, 2003. Proceedings. 2003 International Conference on}, 
title={Probabilistic validation of an intrusion-tolerant replication system}, 
year={2003}, 
month={june}, 
volume={}, 
number={}, 
pages={ 615 - 624}, 
abstract={Not available}, 
keywords={}, 
doi={10.1109/DSN.2003.1209971}, 
ISSN={},}

@inproceedings{courtney2002providing,
  title={Providing intrusion tolerance with ITUA},
  author={Courtney, T. and Lyons, J. and Ramasamy, HV and Sanders, W.H. and Seri, M. and Atighetchi, M. and Rubel, P. and Jones, C. and Webber, F. and Pal, P. and others},
  booktitle={Supplemental Volume Int. Conf. on Dependable Systems \& Networks (DSN-2002)},
  pages={23--26},
  year={2002},
  organization={Citeseer}
}

@INPROCEEDINGS{5480808, 
author={Ha Thanh Le and Subramanian, D. and Wen Jing Hsu and Loh, P.K.K.}, 
booktitle={Advanced Information Networking and Applications Workshops (WAINA), 2010 IEEE 24th International Conference on}, 
title={Scoring Web-Based Vulnerability Impact Using Property-Based Vulnerability Model}, 
year={2010}, 
month={april}, 
volume={}, 
number={}, 
pages={431 -436}, 
abstract={This work extends our proposed property-based vulnerability model (VPRG and VPRM) to score the impact of vulnerabilities by: (1) using the model to distinguish the cause- and consequence- factors that later affect the impact score of vulnerabilities and (2) using the scoring algorithm that considers the relationship of properties evolving in the cause- and consequence-set. We use this scoring framework in determining the impact scores of some web-based and web-related vulnerabilities.}, 
keywords={cause and consequence factors;property-based vulnerability model;scoring Web-based vulnerability;scoring algorithm;Internet;security of data;}, 
doi={10.1109/WAINA.2010.123}, 
ISSN={},}

@INPROCEEDINGS{4573035, 
author={Maggi, P. and Pozza, D. and Sisto, R.}, 
booktitle={Dependability of Computer Systems, 2008. DepCos-RELCOMEX '08. Third International Conference on}, 
title={Vulnerability Modelling for the Analysis of Network Attacks}, 
year={2008}, 
month={june}, 
volume={}, 
number={}, 
pages={15 -22}, 
abstract={In order to perform a successful attack on a network, an intruder must know various penetration techniques, also known as exploits. In general, an exploit can be successful only if some pre-conditions are true. Such conditions may involve the presence of vulnerable programs and/or specific software configurations, as well as certain attacker privileges on hosts and network reachability. When an exploit has success, it usually induces a new set of conditions within the network (post-conditions), such as new attacker privileges, and increased connectivity. Therefore, a network attack can be made of a series of exploits that gradually increase the attacker "power" on the network, until some final goal has been reached or the whole network has been compromised. Reaching such a goal is possible because of dependencies among exploits in terms of pre- and post-conditions. This paper describes how the OVAL language, originally aimed at describing how to check for the existence of vulnerabilities on hosts, can be enhanced to allow automatic reasoning for precisely determining the possible chains of exploits that an attacker could use to compromise the hosts in the network. Moreover, the paper shows how the description of vulnerabilities can be enriched to allow performing risk analysis, so as to determine the impact of attackers on the network, as well as the likelihood of attacks.}, 
keywords={network attacks analysis;risk analysis;software configurations;vulnerability modelling;security of data;software engineering;}, 
doi={10.1109/DepCoS-RELCOMEX.2008.49}, 
ISSN={},}

@INPROCEEDINGS{5641988, 
author={Yi Hu and Campan, A. and Walden, J. and Vorobyeva, I. and Shelton, J.}, 
booktitle={Systems Man and Cybernetics (SMC), 2010 IEEE International Conference on}, 
title={An effective log mining approach for database intrusion detection}, 
year={2010}, 
month={oct.}, 
volume={}, 
number={}, 
pages={2299 -2306}, 
abstract={Organizations spend a significant amount of resources securing their servers and network perimeters. However, these mechanisms are not sufficient for protecting databases. In this paper, we present a new technique for identifying malicious database transactions. Compared to many existing approaches which profile SQL query structures and database user activities to detect intrusions, the novelty of this approach is the automatic discovery and use of essential data dependencies, namely, multi-dimensional and multi-level data dependencies, for identifying anomalous database transactions. Since essential data dependencies reflect semantic relationships among data items and are less likely to change than SQL query structures or database user behaviors, they are ideal for profiling data correlations for identifying malicious database activities.}, 
keywords={database intrusion detection;database user activities;log mining approach;malicious database transactions;multidimensional data dependency;multilevel data dependency;profile SQL query structures;SQL;data mining;relational databases;security of data;}, 
doi={10.1109/ICSMC.2010.5641988}, 
ISSN={1062-922X},}

@INPROCEEDINGS{4708863, 
author={Chrun, D. and Cukier, M. and Sneeringer, G.}, 
booktitle={High Assurance Systems Engineering Symposium, 2008. HASE 2008. 11th IEEE}, 
title={On the Use of Security Metrics Based on Intrusion Prevention System Event Data: An Empirical Analysis}, 
year={2008}, 
month={dec.}, 
volume={}, 
number={}, 
pages={49 -58}, 
abstract={With the increasing number of attacks on the Internet, a primary concern for organizations is the protection of their network. To do so, organizations install security devices such as intrusion prevention systems to monitor network traffic. However, data that are collected by these devices are often imperfect. The contribution of this paper is to try to define some practical metrics based on imperfect data collected by an intrusion prevention system. Since attacks greatly differ, we propose to group the attacks into several attack type groups. We then define a set of metrics for each attack type group. We introduce an approach that consists in analyzing the evolution of these metrics per attack type group by focusing on outliers in order to give an insight into an organizationpsilas security. The method is assessed for an organization of about 40,000 computers. The results were encouraging: outliers could be related to security issues that, in some cases, had not been previously flagged.}, 
keywords={Internet attack group;empirical analysis;intrusion prevention system event data;network traffic monitoring;organization security metrics;Internet;security of data;}, 
doi={10.1109/HASE.2008.52}, 
ISSN={1530-2059},}

@INPROCEEDINGS{1544729, 
author={Tamizi, M. and Weinstein, M. and Cukier, M.}, 
booktitle={Software Reliability Engineering, 2005. ISSRE 2005. 16th IEEE International Symposium on}, 
title={Automated checking for Windows host vulnerabilities}, 
year={2005}, 
month={nov.}, 
volume={}, 
number={}, 
pages={10 pp. -148}, 
abstract={Evaluation of computing system security requires knowledge of the vulnerabilities present in the system and of potential attacks against the system. Vulnerabilities can be classified based on their location as application vulnerabilities, network vulnerabilities, or host vulnerabilities. This paper describes Ferret-Windows, a new software tool for checking host vulnerabilities on the Windows platforms. This tool helps system administrators by quickly finding vulnerabilities that are present on a host. It is designed and implemented in a modular way: a plug-in module is used for each vulnerability checked, and each possible output format is specified by a plug-in module. Moreover, several vulnerability fixing plug-in modules exist to help users remove specific vulnerabilities. As a result, Ferret-Windows is extensible, and can easily be kept up-to-date through the addition of checks for new vulnerabilities as they are identified. Finally, Ferret-Windows is a freely available open-source software}, 
keywords={Ferret-Windows software tool;Windows host vulnerability checking;Windows platforms;application vulnerabilities;computing system security;host vulnerabilities;network vulnerabilities;open-source software;plug-in module;system attacks;operating systems (computers);program diagnostics;security of data;software reliability;software tools;}, 
doi={10.1109/ISSRE.2005.11}, 
ISSN={1071-9458},}

@ARTICLE{4768653, 
author={Cukier, M. and Panjwani, S.}, 
journal={Security Privacy, IEEE}, 
title={Prioritizing Vulnerability Remediation by Determining Attacker-Targeted Vulnerabilities}, 
year={2009}, 
month={jan.-feb. }, 
volume={7}, 
number={1}, 
pages={42 -48}, 
abstract={This article attempts to empirically analyze which vulnerabilities attackers tend to target in order to prioritize vulnerability remediation. This analysis focuses on the link between malicious connections and vulnerabilities, where each connection is considered malicious. Attacks requiring multiple connections are counted as multiple attacks. As the number of connections increases, so does the cost of recovering from the intrusion. The authors deployed four honey pots for four months, each running a different Windows service pack with its associated set of vulnerabilities. They then performed three empirical analyses to determine the relationship between the number of malicious connections and the total number of vulnerabilities, the number of malicious connections and the number of the vulnerabilities for different services, and the number of known successful attacks and the number of vulnerabilities for different services.}, 
keywords={Windows service pack;attacker-targeted vulnerabilities;intrusion detection;malicious connections;vulnerability remediation;security of data;}, 
doi={10.1109/MSP.2009.13}, 
ISSN={1540-7993},}

@article{molina2009evaluating,
  title={Evaluating Attack Resiliency for Host Intrusion Detection Systems},
  author={Molina, J. and Cukier, M.},
  journal={Information Assurance and Security Journal},
  volume={4},
  pages={1--9},
  year={2009}
}

#

@inproceedings{sufatrio2011quantifying,
  title={Quantifying the Effects of More Timely Certificate Revocation on Lightweight Mobile Devices},
  author={Sufatrio, S and Yap, RHC},
  booktitle={Security Measurements and Metrics (Metrisec), 2011 Third International Workshop on},
  pages={31--40},
  year={2011},
  organization={IEEE}
}

@INPROCEEDINGS{testbedpaper
,	author	= {Stuckman, J. and Purtilo, J.}
,	title	= {A Testbed for the Evaluation of Web Intrusion Prevention Systems}
,	booktitle	= {Proceedings of MetriSec 2011 International Workshop on Security Measurements and Metrics}
,	year	= {2011}
,	pages	= {66 -75}
,	publisher	= {IEEE}
,	month	= {Sept}
,	abstract	= {Web intrusion prevention systems are popular for defending web applications against common attacks, such as SQL injection and cross-site scripting, but a standardized methodology to evaluate and benchmark such systems is not available. We outline several requirements for a testing and evaluation framework for these systems, and we introduce the concept of a benchmarking testbed, which automatically performs the evaluation in a standardized and reproducible way. By allowing benchmarks to draw from a corpus of installable modules which can be based on actual security vulnerabilities, members of the security community can continuously maintain and improve the benchmark, allowing it to be updated as threats and defenses evolve. We developed a prototype of this testbed and determined that the testbed should automate several common web testing tasks on behalf of its modules in order to ease module development. Although our experiences with the prototype suggest that developing such a testbed is viable, we identified several open questions related to benchmark coverage and performance measurement that should be resolved in order for the resulting benchmark to be useful to end users.}
,	keywords	= {SQL injection attack;Web application;Web intrusion prevention system;Web testing task;benchmarking testbed concept;cross-site scripting attck;module development;security vulnerability;Internet;security of data;}
,	doi	= {10.1109/Metrisec.2011.14}
}

@inproceedings{causeeffect
,	author	= {Pirzadeh, L. and Jonsson, E.}
,	title	= {A Cause and Effect Approach Towards Risk Analysis}
,	booktitle	= {International workshop on Security Measurements and Metrics-MetriSec2011, Banff, Alberta, Canada, 2011-09-21}
,	year	= {2011}
}

@inproceedings{mcqueen2011vulnerability,
  title={Are Vulnerability Disclosure Deadlines Justified?},
  author={McQueen, Miles and Wright, Jason L and Wellman, Lawrence},
  booktitle={Security Measurements and Metrics (Metrisec), 2011 Third International Workshop on},
  pages={96--101},
  year={2011},
  organization={IEEE}
}

@inproceedings{experiencesindicators
,	author	= {Ligaarden, Olav S and Refsdal, Atle and Stolen, Ketil}
,	title	= {Experiences from Using Indicators to Validate Expert Judgments in Security Risk Analysis}
,	booktitle	= {Security Measurements and Metrics (Metrisec), 2011 Third International Workshop on}
,	year	= {2011}
,	pages	= {88--95}
,	organization	= {IEEE}
}

@inproceedings{kowalski2011cyber,
  title={Cyber Security Alert Warning System: A Socio-techinal Coordinate System Proposal},
  author={Kowalski, Stewart and Barabanov, Rostyslav and Hoffmann, Robert},
  booktitle={Security Measurements and Metrics (Metrisec), 2011 Third International Workshop on},
  pages={21--24},
  year={2011},
  organization={IEEE}
}

@inproceedings{kohli2011enhanced,
  title={An Enhanced Threat Identification Approach for Collusion Threats},
  author={Kohli, Harpreet and Lindskog, Dale and Zavarsky, Pavol and Ruhl, Ron},
  booktitle={Security Measurements and Metrics (Metrisec), 2011 Third International Workshop on},
  pages={25--30},
  year={2011},
  organization={IEEE}
}

@inproceedings{jonsson2011framework,
  title={A Framework for Security Metrics Based on Operational System Attributes},
  author={Jonsson, E. and Pirzadeh, L.},
  booktitle={International workshop on Security Measurements and Metrics-MetriSec2011, Banff, Alberta, Canada, 2011-09-21.},
  year={2011}
}

@inproceedings{jang2011authentication,
  title={Authentication Protocol for Preventing Damage by Loss and Theft of Smartphone},
  author={Jang, Ki-Hun and Youm, Heung-Youl},
  booktitle={Security Measurements and Metrics (Metrisec), 2011 Third International Workshop on},
  pages={76--79},
  year={2011},
  organization={IEEE}
}

@inproceedings{elahi2011security,
  title={Security Risk Management by Qualitative Vulnerability Analysis},
  author={Elahi, G. and Yu, E. and Zannone, N.},
  booktitle={Proceedings of the 7th International Workshop on Security Measurements and Metrics, Banff, Alberta, Canada},
  volume={21},
  year={2011}
}

@inproceedings{evolutionphp
,	author	= {Doyle, Maureen and Walden, James}
,	title	= {An Empirical Study of the Evolution of PHP Web Application Security}
,	booktitle	= {Security Measurements and Metrics (Metrisec), 2011 Third International Workshop on}
,	year	= {2011}
,	pages	= {11--20}
,	organization	= {IEEE}
}

@inproceedings{demetz2011performance,
  title={Performance measurement in cross-organizational security settings},
  author={Demetz, Lukas and Thalmann, Stefan and Bachlechner, Daniel and Maier, Ronald},
  booktitle={Security Measurements and Metrics (Metrisec), 2011 Third International Workshop on},
  pages={84--87},
  year={2011},
  organization={IEEE}
}

@inproceedings{banescu2011measuring,
  title={Measuring Privacy Compliance with Process Specifications},
  author={Banescu, S. and Zannone, N.},
  booktitle={Proceedings of the 7th International Workshop on Security Measurements and Metrics, Banff, Alberta, Canada},
  volume={21},
  year={2011}
}

@INPROCEEDINGS{6092563, 
author={Stolee, K.T. and Elbaum, S. and Sarma, A.}, 
booktitle={Empirical Software Engineering and Measurement (ESEM), 2011 International Symposium on}, 
title={End-User Programmers and their Communities: An Artifact-based Analysis}, 
year={2011}, 
month={sept.}, 
volume={}, 
number={}, 
pages={147 -156}, 
abstract={End-user programmers outnumber professionals programmers, write software that matters to an increasingly large number of users, and face software engineering challenges that are similar to their professionals counterparts. Yet, we know little about how these end-user programmers create and share artifacts as part of a community. To gain a better understanding of these issues, we perform an artifact-based community analysis of 32,000 mashups from the Yahoo! Pipes repository. We observed that, like with other online communities, there is great deal of attrition but authors that persevere tend to improve over time, creating pipes that are more configurable, diverse, complex, and popular. We also discovered, however, that end-user programmers employ the repository in different ways than professionals, do not effectively reuse existing programs, and in most cases do not have an awareness of the community. We discuss the implications of these findings.}, 
keywords={Yahoo! Pipes repository;artifact based community analysis;end user programmers;program reuse;software engineering;software reusability;}, 
doi={10.1109/ESEM.2011.23}, 
ISSN={1938-6451},}

@INPROCEEDINGS{6092560, 
author={Xiao Qu and Robinson, B.}, 
booktitle={Empirical Software Engineering and Measurement (ESEM), 2011 International Symposium on}, 
title={A Case Study of Concolic Testing Tools and their Limitations}, 
year={2011}, 
month={sept.}, 
volume={}, 
number={}, 
pages={117 -126}, 
abstract={Automatic testing, in particular test input generation, has become increasingly popular in the research community over the past ten years. In this paper, we conduct a survey on existing concolic testing tools, discussing their strengths and limitations, and environments in which they can be applied. We also conduct a case study to determine the prevalence of the identified limitations in six large software systems (four from open-source and two from ABB), as well as the effectiveness and scalability of the publicly available tools. The results show that pointers and native calls are the most prevalent limitations, preventing tools from generating high branch coverage lest eases, and variables of float type are the least prevalent. The scalability of the publically available tools is also a limitation for industrial use, due to the large overhead of creating a test harness. Finally, we propose suggestions on how practitioners can use these tools and how researchers can improve concolic testing.}, 
keywords={automatic testing;concolic testing tools;open source software;software systems;program testing;}, 
doi={10.1109/ESEM.2011.20}, 
ISSN={1938-6451},}

@INPROCEEDINGS{6092559, 
author={Barreiros, E. and Almeida, A. and Saraiva, J. and Soares, S.}, 
booktitle={Empirical Software Engineering and Measurement (ESEM), 2011 International Symposium on}, 
title={A Systematic Mapping Study on Software Engineering Testbeds}, 
year={2011}, 
month={sept.}, 
volume={}, 
number={}, 
pages={107 -116}, 
abstract={Even though empirical research has grown in interest, techniques, methodologies and best practices are still in debate. In this context, test beds are effective when one needs to evaluate and compare technologies. The concept is well disseminated in other areas such as Computer Networks, but remains poorly explored in Software Engineering (SE). This paper presents a systematic mapping study on the SE test beds literature. From the initial set of 4239 studies, 13 primary studies were selected and categorized. Based on that, we found that Software Architecture is the most investigated topic, controlled experiment is the most used method to evaluate such test beds, 20 benefits of using test beds in SE have been identified and that test beds comprise very heterogeneous structural elements.}, 
keywords={SE;computer networks;software architecture;software engineering testbeds;systematic mapping study;software architecture;}, 
doi={10.1109/ESEM.2011.19}, 
ISSN={1938-6451},}

@INPROCEEDINGS{onetechnique
,	author	= {Austin, A. and Williams, L.}
,	title	= {One Technique is Not Enough: A Comparison of Vulnerability Discovery Techniques}
,	booktitle	= {Empirical Software Engineering and Measurement (ESEM), 2011 International Symposium on}
,	year	= {2011}
,	pages	= {97 -106}
,	month	= {sept.}
,	abstract	= {Security vulnerabilities discovered later in the development cycle are more expensive to fix than those discovered early. Therefore, software developers should strive to discover vulnerabilities as early as possible. Unfortunately, the large size of code bases and lack of developer expertise can make discovering software vulnerabilities difficult. To ease this difficulty, many different types of techniques have been devised to aid developers in vulnerability discovery. The goal of this research is to improve vulnerability detection by comparing the effectiveness of vulnerability discovery techniques and to provide specific recommendations to improve vulnerability discovery with these techniques. We conducted a case study on two electronic health record systems to compare four discovery techniques: systematic and exploratory manual penetration testing, static analysis, and automated penetration testing. In our case study, we found empirical evidence that no single technique discovered every type of vulnerability. We discovered almost no individual vulnerabilities with multiple discovery techniques. We also found that systematic manual penetration testing found the most design flaws, while static analysis found the most implementation bugs. Finally, we found the most effective vulnerability discovery technique in terms of vulnerabilities discovered per hour was automated penetration testing. These results suggest that if one has limited time to preform vulnerability discovery one should conduct automated penetration testing to discover implementation bugs and systematic manual penetration testing to discover design flaws.}
,	keywords	= {automated penetration testing;electronic health record systems;exploratory manual penetration;security vulnerabilities;software developers;software vulnerabilities;static analysis;vulnerability discovery technique comparison;security of data;software engineering;}
,	doi	= {10.1109/ESEM.2011.18}
,	issn	= {1938-6451}
}

@INPROCEEDINGS{mardziel11belief,
  TITLE = {Dynamic Enforcement of Knowledge-based Security Policies},
  AUTHOR = {Piotr Mardziel and Stephen Magill and Michael Hicks and Mudhakar Srivatsa},
  BOOKTITLE = {Proceedings of the Computer Security Foundations Symposium (CSF)},
  YEAR = 2011,
  MONTH = JUN
}

@article{Dwork:2011:FFP:1866739.1866758,
 author = {Dwork, Cynthia},
 title = {A firm foundation for private data analysis},
 journal = {Commun. ACM},
 issue_date = {January 2011},
 volume = {54},
 issue = {1},
 month = jan,
 year = {2011},
 issn = {0001-0782},
 pages = {86--95},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1866739.1866758},
 doi = {http://doi.acm.org/10.1145/1866739.1866758},
 acmid = {1866758},
 publisher = {ACM},
 address = {New York, NY, USA},
} 


@inproceedings{Brumley:2003:RTA:1251353.1251354,
 author = {Brumley, David and Boneh, Dan},
 title = {Remote timing attacks are practical},
 booktitle = {Proceedings of the 12th conference on USENIX Security Symposium - Volume 12},
 year = {2003},
 location = {Washington, DC},
 pages = {1--1},
 numpages = {1},
 url = {http://dl.acm.org/citation.cfm?id=1251353.1251354},
 acmid = {1251354},
 publisher = {USENIX Association},
 address = {Berkeley, CA, USA},
} 


@inproceedings{Askarov:2010:PBM:1866307.1866341,
 author = {Askarov, Aslan and Zhang, Danfeng and Myers, Andrew C.},
 title = {Predictive black-box mitigation of timing channels},
 booktitle = {Proceedings of the 17th ACM conference on Computer and communications security},
 series = {CCS '10},
 year = {2010},
 isbn = {978-1-4503-0245-6},
 location = {Chicago, Illinois, USA},
 pages = {297--307},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/1866307.1866341},
 doi = {http://doi.acm.org/10.1145/1866307.1866341},
 acmid = {1866341},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {information flow, mitigation, timing channels},
} 


@article{newsome2005dynamic,
  title={Dynamic taint analysis for automatic detection, analysis, and signature generation of exploits on commodity software},
  author={Newsome, James and Song, Dawn},
  year={2005},
  publisher={Internet Society}
}

@article{clarkson2009quantifying,
  title={Quantifying information flow with beliefs},
  author={Clarkson, M.R. and Myers, A.C. and Schneider, F.B.},
  journal={Journal of Computer Security},
  volume={17},
  number={5},
  pages={655--701},
  year={2009},
  publisher={IOS Press}
}

@article{sabelfeld2003language,
  title={Language-based information-flow security},
  author={Sabelfeld, A. and Myers, A.C.},
  journal={Selected Areas in Communications, IEEE Journal on},
  volume={21},
  number={1},
  pages={5--19},
  year={2003},
  publisher={IEEE}
}

@inproceedings{Perkins:2009:APE:1629575.1629585,
 author = {Perkins, Jeff H. and Kim, Sunghun and Larsen, Sam and Amarasinghe, Saman and Bachrach, Jonathan and Carbin, Michael and Pacheco, Carlos and Sherwood, Frank and Sidiroglou, Stelios and Sullivan, Greg and Wong, Weng-Fai and Zibin, Yoav and Ernst, Michael D. and Rinard, Martin},
 title = {Automatically patching errors in deployed software},
 booktitle = {Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles},
 series = {SOSP '09},
 year = {2009},
 isbn = {978-1-60558-752-3},
 location = {Big Sky, Montana, USA},
 pages = {87--102},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/1629575.1629585},
 doi = {http://doi.acm.org/10.1145/1629575.1629585},
 acmid = {1629585},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {self healing},
} 

@inproceedings{Sidiroglou:2009:AAS:1508244.1508250,
 author = {Sidiroglou, Stelios and Laadan, Oren and Perez, Carlos and Viennot, Nicolas and Nieh, Jason and Keromytis, Angelos D.},
 title = {ASSURE: automatic software self-healing using rescue points},
 booktitle = {Proceedings of the 14th international conference on Architectural support for programming languages and operating systems},
 series = {ASPLOS '09},
 year = {2009},
 isbn = {978-1-60558-406-5},
 location = {Washington, DC, USA},
 pages = {37--48},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1508244.1508250},
 doi = {http://doi.acm.org/10.1145/1508244.1508250},
 acmid = {1508250},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {binary patching, chekpoint restart, error recovery, reliable software, software self-healing},
} 


@inproceedings{nvariant
,	author	= {Cox, Benjamin and Evans, David and Filipi, Adrian and Rowanhill, Jonathan and Hu, Wei and Davidson, Jack and Knight, John and Nguyen-Tuong, Anh and Hiser, Jason}
,	title	= {N-variant systems: a secretless framework for security through diversity}
,	booktitle	= {Proceedings of the 15th conference on USENIX Security Symposium - Volume 15}
,	year	= {2006}
,	publisher	= {USENIX Association}
,	address	= {Berkeley, CA, USA}
,	location	= {Vancouver, B.C., Canada}
,	articleno	= {9}
,	url	= {http://dl.acm.org/citation.cfm?id=1267336.1267344}
,	acmid	= {1267344}
}

@inproceedings{Shacham:2004:EAR:1030083.1030124,
 author = {Shacham, Hovav and Page, Matthew and Pfaff, Ben and Goh, Eu-Jin and Modadugu, Nagendra and Boneh, Dan},
 title = {On the effectiveness of address-space randomization},
 booktitle = {Proceedings of the 11th ACM conference on Computer and communications security},
 series = {CCS '04},
 year = {2004},
 isbn = {1-58113-961-6},
 location = {Washington DC, USA},
 pages = {298--307},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1030083.1030124},
 doi = {http://doi.acm.org/10.1145/1030083.1030124},
 acmid = {1030124},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {address-space randomization, automated attacks, diversity},
} 

@article{cfi
,	author	= {Abadi, Mart\'\in and Budiu, Mihai and Erlingsson, \'Ulfar and Ligatti, Jay}
,	title	= {Control-flow integrity principles, implementations, and applications}
,	journal	= {ACM Trans. Inf. Syst. Secur.}
,	year	= {2009}
,	volume	= {13}
,	pages	= {4:1--4:40}
,	month	= {November}
,	issue_date	= {October 2009}
,	issue	= {1}
,	issn	= {1094-9224}
,	articleno	= {4}
,	numpages	= {40}
,	url	= {http://doi.acm.org/10.1145/1609956.1609960}
,	doi	= {http://doi.acm.org/10.1145/1609956.1609960}
,	acmid	= {1609960}
,	publisher	= {ACM}
,	address	= {New York, NY, USA}
,	keywords	= {Binary rewriting, control-flow graph, inlined reference monitors, vulnerabilities}
}

@inproceedings{Shacham:2007:GIF:1315245.1315313,
 author = {Shacham, Hovav},
 title = {The geometry of innocent flesh on the bone: return-into-libc without function calls (on the x86)},
 booktitle = {Proceedings of the 14th ACM conference on Computer and communications security},
 series = {CCS '07},
 year = {2007},
 isbn = {978-1-59593-703-2},
 location = {Alexandria, Virginia, USA},
 pages = {552--561},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1315245.1315313},
 doi = {http://doi.acm.org/10.1145/1315245.1315313},
 acmid = {1315313},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {instruction set, return-into-libc, turing completeness},
} 


@incollection{Erlingsson:2007:LSS:1793914.1793919,
 author = {Erlingsson, \'{U}lfar},
 chapter = {Low-level software security: attacks and defenses},
 title = {Foundations of security analysis and design IV},
 editor = {Aldini, Alessandro and Gorrieri, Roberto},
 year = {2007},
 isbn = {3-540-74809-1, 978-3-540-74809-0},
 pages = {92--134},
 numpages = {43},
 url = {http://dl.acm.org/citation.cfm?id=1793914.1793919},
 acmid = {1793919},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 


@techreport{zeller2008cross,
  title={Cross-site request forgeries: Exploitation and prevention},
  author={Zeller, W. and Felten, E.W.},
  year={2008},
  institution={Technical report, October 2008. http://www. freedom-to-tinker. com/sites/default/files/csrf. pdf}
}

@article{Reshef16122011,
author = {Reshef, David N. and Reshef, Yakir A. and Finucane, Hilary K. and Grossman, Sharon R. and McVean, Gilean and Turnbaugh, Peter J. and Lander, Eric S. and Mitzenmacher, Michael and Sabeti, Pardis C.}, 
title = {Detecting Novel Associations in Large Data Sets}, 
volume = {334}, 
number = {6062}, 
pages = {1518-1524}, 
year = {2011}, 
doi = {10.1126/science.1205438}, 
abstract ={Identifying interesting relationships between pairs of variables in large data sets is increasingly important. Here, we present a measure of dependence for two-variable relationships: the maximal information coefficient (MIC). MIC captures a wide range of associations both functional and not, and for functional relationships provides a score that roughly equals the coefficient of determination (R2) of the data relative to the regression function. MIC belongs to a larger class of maximal information-based nonparametric exploration (MINE) statistics for identifying and classifying relationships. We apply MIC and MINE to data sets in global health, gene expression, major-league baseball, and the human gut microbiota and identify known and novel relationships.}, 
URL = {http://www.sciencemag.org/content/334/6062/1518.abstract}, 
eprint = {http://www.sciencemag.org/content/334/6062/1518.full.pdf}, 
journal = {Science} 
}


@misc{SAMATE
,	howpublished	= {http://samate.nist.gov/SRD/}
}

#

@article{Chandola:2009:ADS:1541880.1541882,
 author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
 title = {Anomaly detection: A survey},
 journal = {ACM Comput. Surv.},
 issue_date = {July 2009},
 volume = {41},
 issue = {3},
 month = {July},
 year = {2009},
 issn = {0360-0300},
 pages = {15:1--15:58},
 articleno = {15},
 numpages = {58},
 url = {http://doi.acm.org/10.1145/1541880.1541882},
 doi = {http://doi.acm.org/10.1145/1541880.1541882},
 acmid = {1541882},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Anomaly detection, outlier detection},
} 


#

#

@inproceedings{Halfond:2005:AAM:1101908.1101935,
 author = {Halfond, William G. J. and Orso, Alessandro},
 title = {AMNESIA: analysis and monitoring for NEutralizing SQL-injection attacks},
 booktitle = {Proceedings of the 20th IEEE/ACM international Conference on Automated software engineering},
 series = {ASE '05},
 year = {2005},
 isbn = {1-58113-993-4},
 location = {Long Beach, CA, USA},
 pages = {174--183},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1101908.1101935},
 doi = {http://doi.acm.org/10.1145/1101908.1101935},
 acmid = {1101935},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {SQL injection, runtime monitoring, static analysis},
} 

@article{geisser2008new,
  title={New applications for wikis in software engineering},
  author={Geisser, M. and Happel, H.J. and Hildenbrand, T. and Korthaus, A. and Seedorf, S.},
  journal={Proceedings of the PRIMIUM Subconference at the Multikonferenz Wirtschaftsinformatik (MKWI)},
  volume={2008},
  year={2008}
}

@inproceedings{bontcheva2006learning,
  title={Learning ontologies from software artifacts: Exploring and combining multiple sources},
  author={Bontcheva, K. and Sabou, M.},
  booktitle={Proceedings of the 2nd International Workshop on Semantic Web Enabled Software Engineering (SWESE 2006)},
  year={2006},
  organization={Citeseer}
}

@article{shiva2008using,
  title={Using semantic wikis to support software reuse},
  author={Shiva, S.G. and Shala, L.A.},
  journal={Journal of Software},
  volume={3},
  number={4},
  pages={1--8},
  year={2008}
}

@inproceedings{chi2008augmented,
  title={Augmented social cognition},
  author={Chi, E.H. and Pirolli, P. and Suh, B. and Kittur, A. and Pendleton, B. and Mytkowicz, T.},
  booktitle={AAAI Spring Symposium on Social Information Processing, California, USA},
  year={2008}
}

@inproceedings{Vikram:2009:RAS:1653662.1653685,
 author = {Vikram, K. and Prateek, Abhishek and Livshits, Benjamin},
 title = {Ripley: automatically securing web 2.0 applications through replicated execution},
 booktitle = {Proceedings of the 16th ACM conference on Computer and communications security},
 series = {CCS '09},
 year = {2009},
 isbn = {978-1-60558-894-0},
 location = {Chicago, Illinois, USA},
 pages = {173--186},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/1653662.1653685},
 doi = {http://doi.acm.org/10.1145/1653662.1653685},
 acmid = {1653685},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {replication, tier-splitting, web applications},
} 


@article{Chong:2009:BSW:1461928.1461949,
 author = {Chong, Stephen and Liu, Jed and Myers, Andrew C. and Qi, Xin and Vikram, K. and Zheng, Lantian and Zheng, Xin},
 title = {Building secure web applications with automatic partitioning},
 journal = {Commun. ACM},
 issue_date = {February 2009},
 volume = {52},
 issue = {2},
 month = feb,
 year = {2009},
 issn = {0001-0782},
 pages = {79--87},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/1461928.1461949},
 doi = {http://doi.acm.org/10.1145/1461928.1461949},
 acmid = {1461949},
 publisher = {ACM},
 address = {New York, NY, USA},
} 


@incollection {springerlink:10.1007/978-3-642-13739-6_15,
   author = {Jayaraman, Karthick and Lewandowski, Grzegorz and Talaga, Paul and Chapin, Steve},
   affiliation = {Department of EECS, Syracuse University},
   title = {Enforcing Request Integrity in Web Applications},
   booktitle = {Data and Applications Security and Privacy XXIV},
   series = {Lecture Notes in Computer Science},
   editor = {Foresti, Sara and Jajodia, Sushil},
   publisher = {Springer Berlin / Heidelberg},
   isbn = {978-3-642-13738-9},
   keyword = {Computer Science},
   pages = {225-240},
   volume = {6166},
   url = {http://dx.doi.org/10.1007/978-3-642-13739-6_15},
   note = {10.1007/978-3-642-13739-6_15},
   year = {2010}
}

@article{cochranserver,
  title={Server-side Verification of Client Behavior in Online Games},
  author={Cochran, D.B.R.A. and Reiter, M.K.}
}

@inproceedings{Guha:2009:USA:1526709.1526785,
 author = {Guha, Arjun and Krishnamurthi, Shriram and Jim, Trevor},
 title = {Using static analysis for Ajax intrusion detection},
 booktitle = {Proceedings of the 18th international conference on World wide web},
 series = {WWW '09},
 year = {2009},
 isbn = {978-1-60558-487-4},
 location = {Madrid, Spain},
 pages = {561--570},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1526709.1526785},
 doi = {http://doi.acm.org/10.1145/1526709.1526785},
 acmid = {1526785},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Ajax, control-flow analysis, intrusion detection, javascript},
} 

@inproceedings{Kaiser:2009:FRA:1653662.1653695,
 author = {Kaiser, Edward and Feng, Wu-chang and Schluessler, Travis},
 title = {Fides: remote anomaly-based cheat detection using client emulation},
 booktitle = {Proceedings of the 16th ACM conference on Computer and communications security},
 series = {CCS '09},
 year = {2009},
 isbn = {978-1-60558-894-0},
 location = {Chicago, Illinois, USA},
 pages = {269--279},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/1653662.1653695},
 doi = {http://doi.acm.org/10.1145/1653662.1653695},
 acmid = {1653695},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {anomaly-based detection, anti-cheating, online games, partial client emulation, remote measurement},
} 

@INPROCEEDINGS{5431756, 
author={Pradel, M. and Gross, T.R.}, 
booktitle={Automated Software Engineering, 2009. ASE '09. 24th IEEE/ACM International Conference on}, 
title={Automatic Generation of Object Usage Specifications from Large Method Traces}, 
year={2009}, 
month={nov.}, 
volume={}, 
number={}, 
pages={371 -382}, 
abstract={Formal specifications are used to identify programming errors, verify the correctness of programs, and as documentation. Unfortunately, producing them is error-prone and time-consuming, so they are rarely used in practice. Inferring specifications from a running application is a promising solution. However, to be practical, such an approach requires special techniques to treat large amounts of runtime data. We present a scalable dynamic analysis that infers specifications of correct method call sequences on multiple related objects. It preprocesses method traces to identify small sets of related objects and method calls which can be analyzed separately. We implemented our approach and applied the analysis to eleven real-world applications and more than 240 million runtime events. The experiments show the scalability of our approach. Moreover, the generated specifications describe correct and typical behavior, and match existing API usage documentation.}, 
keywords={API usage documentation;correct method call sequences;formal specifications;large method traces;object-oriented applications;program correctness verification;programming errors;scalable dynamic analysis;application program interfaces;formal specification;object-oriented methods;program diagnostics;program verification;}, 
doi={10.1109/ASE.2009.60}, 
ISSN={1527-1366},}

@inproceedings{walden2010java
,	author	= {Walden, J. and Doyle, M. and Lenhof, R. and Murray, J.}
,	title	= {Java vs. PHP: Security Implications of Language Choice for Web Applications}
,	booktitle	= {International Symposium on Engineering Secure Software and Systems (ESSoS)(February 2010)}
,	year	= {2010}
}

@article{mcleanproving,
  title={Proving Noninterference and Functional Correctness Using Traces},
  author={McLean, J.}
  
}

@article{hofmeyr1998intrusion,
  title={Intrusion detection using sequences of system calls},
  author={Hofmeyr, S.A. and Forrest, S. and Somayaji, A.},
  journal={Journal of computer security},
  volume={6},
  number={3},
  pages={151--180},
  year={1998},
  publisher={IOS Press}
}

@inproceedings{Plantec:2009:BSV:1639950.1640006,
 author = {Plantec, Alain and Ribaud, Vincent and Varma, Vasudeva},
 title = {Building a semantic virtual museum: from Wiki to semantic Wiki using named entity recognition},
 booktitle = {Proceedings of the 24th ACM SIGPLAN conference companion on Object oriented programming systems languages and applications},
 series = {OOPSLA '09},
 year = {2009},
 isbn = {978-1-60558-768-4},
 location = {Orlando, Florida, USA},
 pages = {769--770},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/1639950.1640006},
 doi = {http://doi.acm.org/10.1145/1639950.1640006},
 acmid = {1640006},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {information extraction, ontology, semantic wiki},
} 


@mastersthesis{de2010automated,
  title={Automated Security Review of PHP Web Applications with Static Code Analysis},
  author={de Poel, N.L. and Brokken, F.B. and de Lavalette, G.R.R.},
  year={2010},
  school={Master’s thesis, State University of Groningen}
}

@incollection {springerlink:10.1007/978-3-642-05089-3_50,
   author = {Alpuente, María and Ballis, Demis and Romero, Daniel},
   affiliation = {Universidad Politécnica de Valencia Camino de Vera s/n, Apdo 22012 46071 Valencia Spain},
   title = {Specification and Verification of Web Applications in Rewriting Logic},
   booktitle = {FM 2009: Formal Methods},
   series = {Lecture Notes in Computer Science},
   editor = {Cavalcanti, Ana and Dams, Dennis},
   publisher = {Springer Berlin / Heidelberg},
   isbn = {978-3-642-05088-6},
   keyword = {Computer Science},
   pages = {790-805},
   volume = {5850},
   url = {http://dx.doi.org/10.1007/978-3-642-05089-3_50},
   note = {10.1007/978-3-642-05089-3_50},
   abstract = {This paper presents a Rewriting Logic framework that formalizes the interactions between Web servers and Web browsers through a communicating protocol abstracting HTTP. The proposed framework includes a scripting language that is powerful enough to model the dynamics of complex Web applications by encompassing the main features of the most popular Web scripting languages (e.g. PHP, ASP, Java Servlets). We also provide a detailed characterization of browser actions (e.g. forward/backward navigation, page refresh, and new window/tab openings) via rewrite rules, and show how our models can be naturally model-checked by using the Linear Temporal Logic of Rewriting (LTLR), which is a Linear Temporal Logic specifically designed for model-checking rewrite theories. Our formalization is particularly suitable for verification purposes, since it allows one to perform in-depth analyses of many subtle aspects related to Web interaction. Finally, the framework has been completely implemented in Maude, and we report on some successful experiments that we conducted by using the Maude LTLR model-checker.},
   year = {2009}
}

@inproceedings{Bezemer:2009:AST:1595696.1595711,
 author = {Bezemer, Cor-Paul and Mesbah, Ali and van Deursen, Arie},
 title = {Automated security testing of web widget interactions},
 booktitle = {Proceedings of the the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering},
 series = {ESEC/FSE '09},
 year = {2009},
 isbn = {978-1-60558-001-2},
 location = {Amsterdam, The Netherlands},
 pages = {81--90},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1595696.1595711},
 doi = {http://doi.acm.org/10.1145/1595696.1595711},
 acmid = {1595711},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {security testing, web applications},
} 

@inproceedings{securedesignpatterns
,	author	= {Dalai, Asish Kumar and Jena, Sanjay Kumar}
,	title	= {Evaluation of web application security risks and secure design patterns}
,	booktitle	= {Proceedings of the 2011 International Conference on Communication, Computing \&\#38; Security}
,	year	= {2011}
,	pages	= {565--568}
,	publisher	= {ACM}
,	address	= {New York, NY, USA}
,	series	= {ICCCS '11}
,	isbn	= {978-1-4503-0464-1}
,	location	= {Rourkela, Odisha, India}
,	numpages	= {4}
,	url	= {http://doi.acm.org/10.1145/1947940.1948057}
,	doi	= {http://doi.acm.org/10.1145/1947940.1948057}
,	acmid	= {1948057}
,	keywords	= {design patterns, security patterns, web application security risks}
}

@article{Alhazmi2007219,
title = "Measuring, analyzing and predicting security vulnerabilities in software systems",
journal = "Computers &amp; Security",
volume = "26",
number = "3",
pages = "219 - 228",
year = "2007",
note = "",
issn = "0167-4048",
doi = "10.1016/j.cose.2006.10.002",
url = "http://www.sciencedirect.com/science/article/pii/S0167404806001520",
author = "O.H. Alhazmi and Y.K. Malaiya and I. Ray",
keywords = "Vulnerabilities",
keywords = "Security holes",
keywords = "Risk evaluation",
keywords = "Quantitative security modeling",
keywords = "Defect density",
abstract = "In this work we examine the feasibility of quantitatively characterizing some aspects of security. In particular, we investigate if it is possible to predict the number of vulnerabilities that can potentially be present in a software system but may not have been found yet. We use several major operating systems as representatives of complex software systems. The data on vulnerabilities discovered in these systems are analyzed. We examine the results to determine if the density of vulnerabilities in a program is a useful measure. We also address the question about what fraction of software defects are security related, i.e., are vulnerabilities. We examine the dynamics of vulnerability discovery hypothesizing that it may lead us to an estimate of the magnitude of the undiscovered vulnerabilities still present in the system. We consider the vulnerability discovery rate to see if models can be developed to project future trends. Finally, we use the data for both commercial and open-source systems to determine whether the key observations are generally applicable. Our results indicate that the values of vulnerability densities fall within a range of values, just like the commonly used measure of defect density for general defects. Our examination also reveals that it is possible to model the vulnerability discovery using a logistic model that can sometimes be approximated by a linear model."
}



@INPROCEEDINGS{4659248, 
author={Hassan, A.E.}, 
booktitle={Frontiers of Software Maintenance, 2008. FoSM 2008.}, 
title={The road ahead for Mining Software Repositories}, 
year={2008}, 
month={28 2008-oct. 4}, 
volume={}, 
number={}, 
pages={48 -57}, 
abstract={Source control repositories, bug repositories, archived communications, deployment logs, and code repositories are examples of software repositories that are commonly available for most software projects. The mining software repositories (MSR) field analyzes and cross-links the rich data available in these repositories to uncover interesting and actionable information about software systems. By transforming these repositories from static record-keeping ones into active repositories, we can guide decision processes in modern software projects. For example, data in source control repositories, traditionally used to archive code, could be linked with data in bug repositories to help practitioners propagate complex changes and to warn them about risky code based on prior changes and bugs. In this paper, we present a brief history of the MSR field and discuss several recent achievements and results of using MSR techniques to support software research and practice. We then discuss the various opportunities and challenges that lie in the road ahead for this important and emerging field.}, 
keywords={archived communications;bug repositories;code repositories;decision processes;deployment logs;mining software repositories field;modern software projects;source control repositories;data mining;decision making;program debugging;project management;software engineering;}, 
doi={10.1109/FOSM.2008.4659248}, 
ISSN={},}

@inproceedings{ye2005benchmark,
  title={A Benchmark Suite for Behavior-Based Security Mechanisms},
  author={Ye, D. and Moffie, M. and Kaeli, D.},
  booktitle={Proceedings of the Workshop on Software Security Assurance Tools, Techniques and Metrics},
  year={2005}
}

@INPROCEEDINGS{4685477, 
author={Sriraghavan, R.G. and Lucchese, L.}, 
booktitle={Machine Learning for Signal Processing, 2008. MLSP 2008. IEEE Workshop on}, 
title={Data processing and anomaly detection in web-based applications}, 
year={2008}, 
month={oct.}, 
volume={}, 
number={}, 
pages={187 -192}, 
abstract={Web applications are popular attack targets. Misuse detection systems use signature databases to detect known attacks. However, it is difficult to keep the database up to date with the rate of discovery of vulnerabilities. They also cannot detect zero-day attacks. By contrast, anomaly detection systems learn the normal behavior of the system and monitor its activity to detect any deviations from the normal. Any such deviations are flagged as anomalous. This paper presents an anomaly detection system for web-based applications. The anomaly detection system monitors the attribute value pairs of successful HTTP requests received by webserver applications and automatically creates parameter profiles. It then uses these profiles to detect anomalies in the HTTP requests. Customized profiles help reduce the number of false positives. Automatic learning ensures that the system can be used with different kinds of web application environments, without the necessity for manual configuration.}, 
keywords={HTTP requests;Web-based applications;anomaly detection;data processing;misuse detection systems;signature databases;webserver applications;zero-day attacks;Internet;data analysis;hypermedia;security of data;}, 
doi={10.1109/MLSP.2008.4685477}, 
ISSN={1551-2541},}

@inproceedings{commandinjection
,	author	= {Su, Zhendong and Wassermann, Gary}
,	title	= {The essence of command injection attacks in web applications}
,	booktitle	= {Conference record of the 33rd ACM SIGPLAN-SIGACT symposium on Principles of programming languages}
,	year	= {2006}
,	pages	= {372--382}
,	publisher	= {ACM}
,	address	= {New York, NY, USA}
,	series	= {POPL '06}
,	isbn	= {1-59593-027-2}
,	location	= {Charleston, South Carolina, USA}
,	numpages	= {11}
,	url	= {http://doi.acm.org/10.1145/1111037.1111070}
,	doi	= {http://doi.acm.org/10.1145/1111037.1111070}
,	acmid	= {1111070}
,	keywords	= {command injection attacks, grammars, parsing, runtime verification, web applications}
}

@inproceedings{GADELRAB:2007:DCS:1314257.1314270,
 author = {GADELRAB, Mohammed S. and El Kalam, Anas Abou and Deswarte, Yves},
 title = {Defining categories to select representative attack test-cases},
 booktitle = {Proceedings of the 2007 ACM workshop on Quality of protection},
 series = {QoP '07},
 year = {2007},
 isbn = {978-1-59593-885-5},
 location = {Alexandria, Virginia, USA},
 pages = {40--42},
 numpages = {3},
 url = {http://doi.acm.org/10.1145/1314257.1314270},
 doi = {http://doi.acm.org/10.1145/1314257.1314270},
 acmid = {1314270},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {attack, classification, evaluation, intrusion detection systems, test},
} 

@mastersthesis{
,	author	= {Alessandri, D.}
,	title	= {Attack-class-based analysis of intrusion detection systems}
,	year	= {2004}
}

@ARTICLE{5464348, 
author={Tavallaee, M. and Stakhanova, N. and Ghorbani, A.A.}, 
journal={Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on}, 
title={Toward Credible Evaluation of Anomaly-Based Intrusion-Detection Methods}, 
year={2010}, 
month={sept. }, 
volume={40}, 
number={5}, 
pages={516 -524}, 
abstract={Since the first introduction of anomaly-based intrusion detection to the research community in 1987, the field has grown tremendously. A variety of methods and techniques introducing new capabilities in detecting novel attacks were developed. Most of these techniques report a high detection rate of 98% at the low false alarm rate of 1%. In spite of the anomaly-based approach's appeal, the industry generally favors signature-based detection for mainstream implementation of intrusion-detection systems. While a variety of anomaly-detection techniques have been proposed, adequate comparison of these methods' strengths and limitations that can lead to potential commercial application is difficult. Since the validity of experimental research in academic computer science, in general, is questionable, it is plausible to assume that research in anomaly detection shares the above problem. The concerns about the validity of these methods may partially explain why anomaly-based intrusion-detection methods are not adopted by industry. To investigate this issue, we review the current state of the experimental practice in the area of anomaly-based intrusion detection and survey 276 studies in this area published during the period of 2000-2008. We summarize our observations and identify the common pitfalls among surveyed works.}, 
keywords={academic computer science;anomaly based intrusion detection methods;signature based detection;security of data;}, 
doi={10.1109/TSMCC.2010.2048428}, 
ISSN={1094-6977},}

@INPROCEEDINGS{1624001, 
author={Cardenas, A.A. and Baras, J.S. and Seamon, K.}, 
booktitle={Security and Privacy, 2006 IEEE Symposium on}, 
title={A framework for the evaluation of intrusion detection systems}, 
year={2006}, 
month={may}, 
volume={}, 
number={}, 
pages={15 pp. -77}, 
keywords={Bayesian detection rate;formal framework;intrusion detection operating characteristic curves;intrusion detection system evaluation;performance evaluation metrics;security of data;software metrics;software performance evaluation;}, 
doi={10.1109/SP.2006.2}, 
ISSN={1081-6011},}

@INPROCEEDINGS{5783404, 
author={Mendes, N. and Duraes, J. and Madeira, H.}, 
booktitle={Dependable Computing (LADC), 2011 5th Latin-American Symposium on}, 
title={Benchmarking the Security of Web Serving Systems Based on Known Vulnerabilities}, 
year={2011}, 
month={april}, 
volume={}, 
number={}, 
pages={55 -64}, 
keywords={Web serving system security;known vulnerabilities;vulnerability exploitability;vulnerability impact;vulnerability severity;vulnerability type frequency;Web services;file servers;security of data;}, 
doi={10.1109/LADC.2011.14}, 
ISSN={},}

@inproceedings{gu2006measuring,
  title={Measuring intrusion detection capability: An information-theoretic approach},
  author={Gu, G. and Fogla, P. and Dagon, D. and Lee, W. and Skori{\'c}, B.},
  booktitle={Proceedings of the 2006 ACM Symposium on Information, computer and communications security},
  pages={90--101},
  year={2006},
  organization={ACM}
}


@inproceedings{maxion2000benchmarking,
  title={Benchmarking anomaly-based detection systems},
  author={Maxion, R.A. and Tan, K.M.C.},
  booktitle={Dependable Systems and Networks, 2000. DSN 2000. Proceedings International Conference on},
  pages={623--630},
  year={2000},
  organization={IEEE}
}

@inproceedings{Wurster:2008:DE:1595676.1595691,
 author = {Wurster, Glenn and van Oorschot, P. C.},
 title = {The developer is the enemy},
 booktitle = {Proceedings of the 2008 workshop on New security paradigms},
 series = {NSPW '08},
 year = {2008},
 isbn = {978-1-60558-341-9},
 location = {Lake Tahoe, California, USA},
 pages = {89--97},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/1595676.1595691},
 doi = {http://doi.acm.org/10.1145/1595676.1595691},
 acmid = {1595691},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {development tools, education, human factors, persuasion, software developers, software security, usability},
} 


@inproceedings{Heckman:2008:EBE:1414004.1414013,
 author = {Heckman, Sarah and Williams, Laurie},
 title = {On establishing a benchmark for evaluating static analysis alert prioritization and classification techniques},
 booktitle = {Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
 series = {ESEM '08},
 year = {2008},
 isbn = {978-1-59593-971-5},
 location = {Kaiserslautern, Germany},
 pages = {41--50},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1414004.1414013},
 doi = {http://doi.acm.org/10.1145/1414004.1414013},
 acmid = {1414013},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {alert classification, alert prioritization, automated static analysis, benchmark creation, false positive mitigation},
} 


@inproceedings{Cifuentes:2009:BBC:1555860.1555866,
 author = {Cifuentes, Cristina and Hoermann, Christian and Keynes, Nathan and Li, Lian and Long, Simon and Mealy, Erica and Mounteney, Michael and Scholz, Bernhard},
 title = {BegBunch: benchmarking for C bug detection tools},
 booktitle = {Proceedings of the 2nd International Workshop on Defects in Large Software Systems: Held in conjunction with the ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA 2009)},
 series = {DEFECTS '09},
 year = {2009},
 isbn = {978-1-60558-654-0},
 location = {Chicago, Illinois},
 pages = {16--20},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/1555860.1555866},
 doi = {http://doi.acm.org/10.1145/1555860.1555866},
 acmid = {1555866},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {accuracy, scalability},
} 


@phdthesis{krsul1998software,
  title={Software vulnerability analysis},
  author={Krsul, I.V.},
  year={1998},
  school={Purdue University}
}

@article{edwards2010afid,
  title={AFID: an automated approach to collecting software faults},
  author={Edwards, A. and Tucker, S. and Demsky, B.},
  journal={Automated Software Engineering},
  volume={17},
  number={3},
  pages={347--372},
  year={2010},
  publisher={Springer}
}

@incollection {springerlink:10.1007/978-3-540-87442-3_84,
   author = {Kang, Hyungwoo},
   affiliation = {Financial Supervisory Service 27 Yoido-dong, Youngdeungpo-gu Seoul 150-743 Korea},
   title = {Security Assessment Framework Using Static Analysis and Fault Injection},
   booktitle = {Advanced Intelligent Computing Theories and Applications. With Aspects of Theoretical and Methodological Issues},
   series = {Lecture Notes in Computer Science},
   editor = {Huang, De-Shuang and Wunsch, Donald and Levine, Daniel and Jo, Kang-Hyun},
   publisher = {Springer Berlin / Heidelberg},
   isbn = {978-3-540-87440-9},
   keyword = {Computer Science},
   pages = {679-687},
   volume = {5226},
   url = {http://dx.doi.org/10.1007/978-3-540-87442-3_84},
   note = {10.1007/978-3-540-87442-3_84},
   abstract = {For large scale and residual software like network service, reliability is a critical requirement. Recent research has shown that most of network software still contains a number of bugs. Methods for automated detection of bugs in software can be classified into static analysis based on formal verification and runtime checking based on fault injection. In this paper, a framework for checking software security vulnerability is proposed. The framework is based on automated bug detection technologies, i.e. static analysis and fault injection, which are complementary each other. The proposed framework provides a new direction, in which various kinds of software can be checked its vulnerability by making use of static analysis and fault injection technology. In experiment on proposed framework, we find unknown vulnerability as well as known vulnerability in Windows network module.},
   year = {2008}
}

@article{wagner2005comparing,
  title={Comparing bug finding tools with reviews and tests},
  author={Wagner, S. and J{\"u}rjens, J. and Koller, C. and Trischberger, P.},
  journal={Testing of Communicating Systems},
  pages={316--316},
  year={2005},
  publisher={Springer}
}

@article{doupé2010johnny,
  title={Why Johnny can’t pentest: an analysis of black-box web vulnerability scanners},
  author={Doup{\'e}, A. and Cova, M. and Vigna, G.},
  journal={Detection of Intrusions and Malware, and Vulnerability Assessment},
  pages={111--131},
  year={2010},
  publisher={Springer}
}

@inproceedings{tian2003common,
  title={Common vulnerability markup language},
  author={Tian, H. and Huang, L. and Zhou, Z. and Zhang, H.},
  booktitle={Applied Cryptography and Network Security},
  pages={228--240},
  year={2003},
  organization={Springer}
}

@incollection {springerlink:10.1007/978-3-642-15512-3_12,
   author = {Wright, Charles and Connelly, Christopher and Braje, Timothy and Rabek, Jesse and Rossey, Lee and Cunningham, Robert},
   affiliation = {Information Systems Technology Group, MIT Lincoln Laboratory, Lexington, MA 02420},
   title = {Generating Client Workloads and High-Fidelity Network Traffic for Controllable, Repeatable Experiments in Computer Security},
   booktitle = {Recent Advances in Intrusion Detection},
   series = {Lecture Notes in Computer Science},
   editor = {Jha, Somesh and Sommer, Robin and Kreibich, Christian},
   publisher = {Springer Berlin / Heidelberg},
   isbn = {978-3-642-15511-6},
   keyword = {Computer Science},
   pages = {218-237},
   volume = {6307},
   url = {http://dx.doi.org/10.1007/978-3-642-15512-3_12},
   note = {10.1007/978-3-642-15512-3_12},
   year = {2010}
}

@inproceedings{newsham2005abm,
  title={ABM: A Prototype for Benchmarking Source Code Analyzers},
  author={Newsham, T. and Chess, B.},
  booktitle={Proceedings of the Workshop on Software Security Assurance Tools, Techniques, and Metrics (SSATTM’05)},
  year={2005}
}

@inproceedings{rightsource
,	author	= {Massacci, Fabio and Nguyen, Viet Hung}
,	title	= {Which is the right source for vulnerability studies?: An empirical analysis on Mozilla Firefox}
,	booktitle	= {Proceedings of MetriSec '10 International Workshop on Security Measurements and Metrics}
,	year	= {2010}
,	pages	= {4:1--4:8}
,	publisher	= {ACM}
,	isbn	= {978-1-4503-0340-8}
,	location	= {Bolzano, Italy}
,	articleno	= {4}
,	numpages	= {8}
,	url	= {http://doi.acm.org/10.1145/1853919.1853925}
,	doi	= {10.1145/1853919.1853925}
,	acmid	= {1853925}
}

@INPROCEEDINGS{testsuitescanners
,	author	= {Fong, E. and Gaucher, R. and Okun, V. and Black, P.E.}
,	title	= {Building a Test Suite for Web Application Scanners}
,	booktitle	= {Hawaii International Conference on System Sciences, Proceedings of the 41st Annual}
,	year	= {2008}
,	pages	= {478}
,	month	= {jan.}
,	abstract	= {This paper describes the design of a test suite for thorough evaluation of web application scanners. Web application scanners are automated, black-box testing tools that examine web applications for security vulnerabilities. For several common vulnerability types, we classify defense mechanisms that can be implemented to prevent corresponding attacks. We combine the defense mechanisms into "levels of defense" of increasing strength. This approach allows us to develop an extensive test suite that can be easily configured to switch on and off vulnerability types and select a level of defense. We evaluate the test suite experimentally using several web application scanners, both open-source and proprietary. The experiments suggest that the test suite is effective at distinguishing the tools based on their vulnerability detection rate; in addition, its use can suggest areas for tool improvement.}
,	keywords	= {Web application scanners;automated black-box testing;security vulnerabilities;test suite;Internet;program testing;security of data;}
,	doi	= {10.1109/HICSS.2008.79}
,	issn	= {1530-1605}
}

@INPROCEEDINGS{predictingdefectseclipse
,	author	= {Zimmermann, T. and Premraj, R. and Zeller, A.}
,	title	= {Predicting Defects for Eclipse}
,	booktitle	= {Predictor Models in Software Engineering, 2007. PROMISE'07: ICSE Workshops 2007. International Workshop on}
,	year	= {2007}
,	pages	= {9}
,	month	= {may}
,	abstract	= {We have mapped defects from the bug database of eclipse (one of the largest open-source projects) to source code locations. The resulting data set lists the number of pre- and post-release defects for every package and file in the eclipse releases 2.0, 2.1, and 3.0. We additionally annotated the data with common complexity metrics. All data is publicly available and can serve as a benchmark for defect prediction models.}
,	keywords	= {Eclipse;bug database;common complexity metrics;defect prediction models;open-source projects;source code locations;program debugging;public domain software;}
,	doi	= {10.1109/PROMISE.2007.10}
}

@inproceedings{elia2010comparing,
  title={Comparing SQL Injection Detection Tools Using Attack Injection: An Experimental Study},
  author={Elia, I.A. and Fonseca, J. and Vieira, M.},
  booktitle={Software Reliability Engineering (ISSRE), 2010 IEEE 21st International Symposium on},
  pages={289--298},
  year={2010},
  organization={IEEE}
}

@INPROCEEDINGS{5552783, 
author={Antunes, N. and Vieira, M.}, 
booktitle={Web Services (ICWS), 2010 IEEE International Conference on}, 
title={Benchmarking Vulnerability Detection Tools for Web Services}, 
year={2010}, 
month={july}, 
volume={}, 
number={}, 
pages={203 -210}, 
abstract={Vulnerability detection tools are frequently considered the silver-bullet for detecting vulnerabilities in web services. However, research shows that the effectiveness of most of those tools is very low and that using the wrong tool may lead to the deployment of services with undetected vulnerabilities. In this paper we propose a benchmarking approach to assess and compare the effectiveness of vulnerability detection tools in web services environments. This approach was used to define a concrete benchmark for SQL Injection vulnerability detection tools. This benchmark is demonstrated by a real example of benchmarking several widely used tools, including four penetration-testers, three static code analyzers, and one anomaly detector. Results show that the benchmark accurately portrays the effectiveness of vulnerability detection tools and suggest that the proposed approach can be applied in the field.}, 
keywords={SQL injection vulnerability detection tools;Web services;benchmarking vulnerability detection tools;silver-bullet;SQL;Web services;software performance evaluation;}, 
doi={10.1109/ICWS.2010.76}, 
ISSN={},}

@INPROCEEDINGS{5542602, 
author={Basso, T. and Fernandes, P.C.S. and Jino, M. and Moraes, R.}, 
booktitle={Dependable Systems and Networks Workshops (DSN-W), 2010 International Conference on}, 
title={Analysis of the effect of Java software faults on security vulnerabilities and their detection by commercial web vulnerability scanner tool}, 
year={2010}, 
month={28 2010-july 1}, 
volume={}, 
number={}, 
pages={150 -155}, 
abstract={Most software systems developed nowadays are highly complex and subject to strict time constraints, and are often deployed with critical software faults. In many cases, software faults are responsible for security vulnerabilities which are exploited by hackers. Automatic web vulnerability scanners can help to locate these vulnerabilities. Trustworthiness of the results that these tools provide is important; hence, relevance of the results must be assessed. We analyze the effect on security vulnerabilities of Java software faults injected on source code of Web applications. We assess how these faults affect the behavior of the scanner vulnerability tool, to validate the results of its application. Software fault injection techniques and attack trees models were used to support the experiments. The injected software faults influenced the application behavior and, consequently, the behavior of the scanner tool. High percentage of uncovered vulnerabilities as well as false positives points out the limitations of the tool.}, 
keywords={Java software faults;commercial Web vulnerability scanner tool;security vulnerabilities;trees models;Internet;Java;security of data;software fault tolerance;}, 
doi={10.1109/DSNW.2010.5542602}, 
ISSN={},}

@inproceedings{programminglanguageperspective
,	author	= {Seixas, Nuno and Fonseca, Jos\'e and Vieira, Marco and Madeira, Henrique}
,	title	= {Looking at Web Security Vulnerabilities from the Programming Language Perspective: A Field Study}
,	booktitle	= {Proceedings of the 2009 20th International Symposium on Software Reliability Engineering}
,	year	= {2009}
,	pages	= {129--135}
,	publisher	= {IEEE Computer Society}
,	address	= {Washington, DC, USA}
,	series	= {ISSRE '09}
,	isbn	= {978-0-7695-3878-5}
,	numpages	= {7}
,	url	= {http://dx.doi.org/10.1109/ISSRE.2009.30}
,	doi	= {http://dx.doi.org/10.1109/ISSRE.2009.30}
,	acmid	= {1682392}
,	keywords	= {Security vulnerabilities, field study, programming languages, software faults}
}

@INPROCEEDINGS{5270349, 
author={Fonseca, J. and Vieira, M. and Madeira, H.}, 
booktitle={Dependable Systems Networks, 2009. DSN '09. IEEE/IFIP International Conference on}, 
title={Vulnerability #x00026; attack injection for web applications}, 
year={2009}, 
month={29 2009-july 2}, 
volume={}, 
number={}, 
pages={93 -102}, 
abstract={In this paper we propose a methodology to inject realistic attacks in Web applications. The methodology is based on the idea that by injecting realistic vulnerabilities in a Web application and attacking them automatically we can assess existing security mechanisms. To provide true to life results, this methodology relies on field studies of a large number of vulnerabilities in Web applications. The paper also describes a set of tools implementing the proposed methodology. They allow the automation of the entire process, including gathering results and analysis. We used these tools to conduct a set of experiments to demonstrate the feasibility and effectiveness of the proposed methodology. The experiments include the evaluation of coverage and false positives of an intrusion detection system for SQL injection and the assessment of the effectiveness of two Web application vulnerability scanners. Results show that the injection of vulnerabilities and attacks is an effective way to evaluate security mechanisms and tools.}, 
keywords={SQL injection;Web application;Web application vulnerability scanner;intrusion detection system;realistic attack injection tool;realistic test bed;realistic vulnerability injection;security mechanism;software bug;Internet;SQL;program debugging;program testing;security of data;}, 
doi={10.1109/DSN.2009.5270349}, 
ISSN={},}

@INPROCEEDINGS{5270294, 
author={Vieira, M. and Antunes, N. and Madeira, H.}, 
booktitle={Dependable Systems Networks, 2009. DSN '09. IEEE/IFIP International Conference on}, 
title={Using web security scanners to detect vulnerabilities in web services}, 
year={2009}, 
month={29 2009-july 2}, 
volume={}, 
number={}, 
pages={566 -571}, 
abstract={Although Web services are becoming business-critical components, they are often deployed with critical software bugs that can be maliciously explored. Web vulnerability scanners allow detecting security vulnerabilities in Web services by stressing the service from the point of view of an attacker. However, research and practice show that different scanners have different performance on vulnerabilities detection. In this paper we present an experimental evaluation of security vulnerabilities in 300 publicly available Web services. Four well known vulnerability scanners have been used to identify security flaws in Web services implementations. A large number of vulnerabilities has been observed, which confirms that many services are deployed without proper security testing. Additionally, the differences in the vulnerabilities detected and the high number of false-positives (35% and 40% in two cases) and low coverage (less than 20% for two of the scanners) observed highlight the limitations of Web vulnerability scanners on detecting security vulnerabilities in Web services.}, 
keywords={Web security scanner;Web services;Web vulnerability scanner;attacker view;business-critical component;code vulnerability analysis;critical software bug;security flaw identification;security testing;security vulnerability detection;Web services;program debugging;program diagnostics;program testing;security of data;}, 
doi={10.1109/DSN.2009.5270294}, 
ISSN={},}

@inproceedings{Fulop:2008:TBE:1447565.1448013,
 author = {F\"{u}l\"{o}p, Lajos Jeno and Hegedus, P\'{e}ter and Ferenc, Rudolf and Gyim\'{o}thy, Tibor},
 title = {Towards a Benchmark for Evaluating Reverse Engineering Tools},
 booktitle = {Proceedings of the 2008 15th Working Conference on Reverse Engineering},
 year = {2008},
 isbn = {978-0-7695-3429-9},
 pages = {335--336},
 numpages = {2},
 url = {http://dl.acm.org/citation.cfm?id=1447565.1448013},
 doi = {10.1109/WCRE.2008.18},
 acmid = {1448013},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {Benchmark, reverse engineering tools, tool evaluation},
} 


@INPROCEEDINGS{4637543, 
author={Di Penta, M. and Cerulo, L. and Aversano, L.}, 
booktitle={Source Code Analysis and Manipulation, 2008 Eighth IEEE International Working Conference on}, 
title={The Evolution and Decay of Statically Detected Source Code Vulnerabilities}, 
year={2008}, 
month={sept.}, 
volume={}, 
number={}, 
pages={101 -110}, 
abstract={The presence of vulnerable statements in the source code is a crucial problem for maintainers: properly monitoring and, if necessary, removing them is highly desirable to ensure high security and reliability. To this aim, a number of static analysis tools have been developed to detect the presence of instructions that can be subject to vulnerability attacks, ranging from buffer overflow exploitations to command injection and cross-site scripting.Based on the availability of existing tools and of data extracted from software repositories, this paper reports an empirical study on the evolution of vulnerable statements detected in three software systems with different static analysis tools. Specifically, the study investigates on vulnerability evolution trends and on the decay time exhibited by different kinds of vulnerabilities.}, 
keywords={buffer overflow exploitations;command injection;cross-site scripting;software repository;software systems;static analysis tools;statically detected source code vulnerability;vulnerability attacks;vulnerable statements;buffer storage;program diagnostics;security of data;software reliability;software tools;}, 
doi={10.1109/SCAM.2008.20}, 
ISSN={},}

@INPROCEEDINGS{mappingfaults
,	author	= {Fonseca, J. and Vieira, M.}
,	title	= {Mapping software faults with web security vulnerabilities}
,	booktitle	= {Proceedings of IEEE DSN '08 Conference on Dependable Systems and Networks}
,	year	= {2008}
,	pages	= {257 -266}
,	abstract	= {Web applications are typically developed with hard time constraints and are often deployed with critical software bugs, making them vulnerable to attacks. The classification and knowledge of the typical software bugs that lead to security vulnerabilities is of utmost importance. This paper presents a field study analyzing 655 security patches of six widely used web applications. Results are compared against other field studies on general software faults (i.e., faults not specifically related to security), showing that only a small subset of software fault types is related to security. Furthermore, the detailed analysis of the code of the patches has shown that web application vulnerabilities result from software bugs affecting a restricted collection of statements. A detailed analysis of the conditions/locations where each fault was observed in our field study is presented allowing future definition of realistic fault models that cause security vulnerabilities in web applications, which is the key element to design a realistic attack injector.}
,	keywords	= {Web application;Web security vulnerabilities;fault models;software bugs;software faults mapping;Internet;security of data;software fault tolerance;}
,	doi	= {10.1109/DSN.2008.4630094}
}

@INPROCEEDINGS{testingscanningtools
,	author	= {Fonseca, J. and Vieira, M. and Madeira, H.}
,	title	= {Testing and Comparing Web Vulnerability Scanning Tools for SQL Injection and XSS Attacks}
,	booktitle	= {Dependable Computing, 2007. PRDC 2007. 13th Pacific Rim International Symposium on}
,	year	= {2007}
,	pages	= {365 -372}
,	month	= {dec.}
,	abstract	= {Web applications are typically developed with hard time constraints and are often deployed with security vulnerabilities. Automatic web vulnerability scanners can help to locate these vulnerabilities and are popular tools among developers of web applications. Their purpose is to stress the application from the attacker's point of view by issuing a huge amount of interaction within it. Two of the most widely spread and dangerous vulnerabilities in web applications are SQL injection and cross site scripting (XSS), because of the damage they may cause to the victim business. Trusting the results of web vulnerability scanning tools is of utmost importance. Without a clear idea on the coverage and false positive rate of these tools, it is difficult to judge the relevance of the results they provide. Furthermore, it is difficult, if not impossible, to compare key figures of merit of web vulnerability scanners. In this paper we propose a method to evaluate and benchmark automatic web vulnerability scanners using software fault injection techniques. The most common types of software faults are injected in the web application code which is then checked by the scanners. The results are compared by analyzing coverage of vulnerability detection and false positives. Three leading commercial scanning tools are evaluated and the results show that in general the coverage is low and the percentage of false positives is very high.}
,	keywords	= {SQL injection;Web vulnerability scanning tool;XSS attack;cross site scripting;software fault injection technique;Internet;SQL;program testing;security of data;software fault tolerance;}
,	doi	= {10.1109/PRDC.2007.55}
}

@INPROCEEDINGS{4041181, 
author={Frederic Massicotte and Francois Gagnon and Yvan Labiche and Lionel Briand and Mathieu Couture}, 
booktitle={Computer Security Applications Conference, 2006. ACSAC '06. 22nd Annual}, 
title={Automatic Evaluation of Intrusion Detection Systems}, 
year={2006}, 
month={dec. }, 
volume={}, 
number={}, 
pages={361 -370}, 
abstract={An intrusion detection system (IDS) is a crucial element of a network security posture. Although there are many IDS products available, it is rather difficult to find information about their accuracy. Only a few organizations evaluate these products. Furthermore, the data used to test and evaluate these IDS is usually proprietary. Thus, the research community cannot easily evaluate the next generation of IDS. Toward this end, DARPA provided in 1998, 1999 and 2000 an intrusion detection evaluation data set. However, no new data set has been released by DARPA since 2000, in part because of the cumbersomeness of the task. In this paper, we propose a strategy to address certain aspects of generating a publicly available documented data set for testing and evaluating intrusion detection systems. We also present a tool that automatically analyzes and evaluates IDS using our proposed data set}, 
keywords={intrusion detection system;network security;traffic trace generation;security of data;}, 
doi={10.1109/ACSAC.2006.15}, 
ISSN={1063-9527},}

@INPROCEEDINGS{1649172, 
author={Benzel, T. and Braden, R. and Kim, D. and Neuman, C. and Joseph, A. and Sklower, K. and Ostrenga, R. and Schwab, S.}, 
booktitle={Testbeds and Research Infrastructures for the Development of Networks and Communities, 2006. TRIDENTCOM 2006. 2nd International Conference on}, 
title={Experience with DETER: a testbed for security research}, 
year={2006}, 
month={0-0 }, 
volume={}, 
number={}, 
pages={10 pp. -388}, 
abstract={The DETER testbed is shared infrastructure designed for medium-scale repeatable experiments in computer security, especially those experiments that involve malicious code. The testbed provides unique resources and a focus of activity for an open community of academic, industry, and government researchers working toward better defenses against malicious attacks on our networking infrastructure, especially critical infrastructure. This paper presents our experience with the deployment and operation of the testbed, highlights some of the research conducted on the testbed, and discusses our plans for continued development, expansion, and replication of the testbed facility}, 
keywords={DETER;malicious code;security research;security of data;telecommunication security;}, 
doi={10.1109/TRIDNT.2006.1649172}, 
ISSN={Not Applica},}

@ARTICLE{miningbugfinding
,	author	= {Williams, C.C. and Hollingsworth, J.K.}
,	title	= {Automatic mining of source code repositories to improve bug finding techniques}
,	journal	= {Software Engineering, IEEE Transactions on}
,	year	= {2005}
,	volume	= {31}
,	number	= {6}
,	pages	= { 466 - 480}
,	month	= {june}
,	abstract	= { We describe a method to use the source code change history of a software project to drive and help to refine the search for bugs. Based on the data retrieved from the source code repository, we implement a static source code checker that searches for a commonly fixed bug and uses information automatically mined from the source code repository to refine its results. By applying our tool, we have identified a total of 178 warnings that are likely bugs in the Apache Web server source code and a total of 546 warnings that are likely bugs in Wine, an open-source implementation of the Windows API. We show that our technique is more effective than the same static analysis that does not use historical data from the source code repository.}
,	keywords	= { Apache Web server; Windows API; automatic mining; bug finding technique; configuration control; data retrieval; debugging aids; historical data; open-source implementation; software project; source code repository; static analysis; static source code checker; testing tools; version control; Internet; application program interfaces; configuration management; data mining; file servers; program debugging; program diagnostics; program testing; public domain software;}
,	doi	= {10.1109/TSE.2005.63}
,	issn	= {0098-5589}
}

@inproceedings{vulnerabilitylikelihood
,	author	= {DaCosta, Dan and Dahn, Christopher and Mancoridis, Spiros and Prevelakis, Vassilis}
,	title	= {Characterizing the `Security Vulnerability Likelihood' of Software Functions}
,	booktitle	= {Proceedings of the IEEE ICSM 2003 International Conference on Software Maintenance}
,	year	= {2003}
,	pages	= {266--}
,	isbn	= {0-7695-1905-9}
,	url	= {http://dl.acm.org/citation.cfm?id=942800.943588}
,	acmid	= {943588}
}

@INPROCEEDINGS{1192459, 
author={Athanasiades, N. and Abler, R. and Levine, J. and Owen, H. and Riley, G.}, 
booktitle={Information Assurance, 2003. IWIAS 2003. Proceedings. First IEEE International Workshop on}, 
title={Intrusion detection testing and benchmarking methodologies}, 
year={2003}, 
month={march}, 
volume={}, 
number={}, 
pages={ 63 - 72}, 
abstract={ The ad-hoc methodology that is prevalent in today's testing and evaluation of network intrusion detection algorithms and systems makes it difficult to compare different algorithms and approaches. After conducting a survey of the literature on the methods and techniques being used, it can be seen that a new approach that incorporates an open source testing methodology and environment would benefit the information assurance community. After summarizing the literature and presenting several example test and evaluation environments that have been used in the past, we propose a new open source evaluation environment and methodology for use by researchers and developers of new intrusion detection and denial of service detection and prevention algorithms and methodologies.}, 
keywords={ benchmarking methodologies; denial of service detection algorithms; hacker tools; information assurance; intrusion detection algorithms; intrusion detection testing; network intrusion detection algorithms; network security; open source evaluation environment; open source testing methodology; computer crime; computer networks; program testing; public domain software; telecommunication security;}, 
doi={10.1109/IWIAS.2003.1192459}, 
ISSN={ },}

@INPROCEEDINGS{1036158, 
author={Rossey, L.M. and Cunningham, R.K. and Fried, D.J. and Rabek, J.C. and Lippmann, R.P. and Haines, J.W. and Zissman, M.A.}, 
booktitle={Aerospace Conference Proceedings, 2002. IEEE}, 
title={LARIAT: Lincoln adaptable real-time information assurance testbed}, 
year={2002}, 
month={}, 
volume={6}, 
number={}, 
pages={ 6-2671-2676, 6-2678 - 6-2682 vol.6}, 
abstract={ The Lincoln adaptable real-time information assurance testbed, LARIAT, is an extension of the testbed created for DARPA 1998 and 1999 intrusion detection (ID) evaluations. LARIAT supports real-time, automated and quantitative evaluations of ID systems and other information assurance (IA) technologies. Components of LARIAT generate realistic background user traffic and real network attacks, verify attack success or failure, score ID system performance, and provide a graphical user interface for control and monitoring. Emphasis was placed on making LARIAT easy to adapt, configure and run without requiring a detailed understanding of the underlying complexity. LARIAT is currently being exercised at four sites and is undergoing continued development and refinement.}, 
keywords={ ID system performance; ID systems; LARIAT Lincoln adaptable real-time information assurance testbed; attack failure; attack success; background user traffic; complexity; graphical user interface; information assurance technologies; intrusion detection; network attacks; real-time automated evaluations; system control; system monitoring; computerised monitoring; data privacy; security of data; telecommunication computing; telecommunication network management; telecommunication security; telecommunication traffic;}, 
doi={10.1109/AERO.2002.1036158}, 
ISSN={ },}

@INPROCEEDINGS{931291, 
author={Champion, T. and Denz, M.L.}, 
booktitle={Aerospace Conference, 2001, IEEE Proceedings.}, 
title={A benchmark evaluation of network intrusion detection systems}, 
year={2001}, 
month={}, 
volume={6}, 
number={}, 
pages={2705 -2712 vol.6}, 
abstract={This paper outlines a benchmarking method for quantifying the detection sensitivity of network intrusion detection systems (IDS) on an important class of denial-of-service (DOS) attacks using the real-time testbed developed at AFRL. This effort involved the development of tunable attack insertion tools and reference software to measure the state of the victim. Two systems were evaluated, a representative signature-based commercial system and a DARPA research system that relies on statistically based techniques. The experiments tried to answer these questions: Are there regions of operation where the attack tool can degrade performance while escaping detection? Is there any added detection power using the research detection system over standard commercial practice? The results can be summarized as follows: the reference victim's performance can be degraded without detection; and the research system had a broader detection region than the commercial system}, 
keywords={DARPA research system;DOS attacks;IDS;benchmark evaluation;denial-of-service attacks;detection sensitivity;network intrusion detection systems;real-time testbed;reference software;representative signature-based commercial system;statistically based techniques;tunable attack insertion tools;computer networks;real-time systems;safety systems;security of data;statistical analysis;}, 
doi={10.1109/AERO.2001.931291}, 
ISSN={},}

@article{alvarez2002encoding,
  title={Encoding a taxonomy of web attacks with different-length vectors},
  author={Alvarez, G. and Petrovic, S.},
  journal={Arxiv preprint cs/0210026},
  year={2002}
}

@article {SMR:SMR344,
author = {Kagdi, Huzefa and Collard, Michael L. and Maletic, Jonathan I.},
title = {A survey and taxonomy of approaches for mining software repositories in the context of software evolution},
journal = {Journal of Software Maintenance and Evolution: Research and Practice},
volume = {19},
number = {2},
publisher = {John Wiley & Sons, Ltd.},
issn = {1532-0618},
url = {http://dx.doi.org/10.1002/smr.344},
doi = {10.1002/smr.344},
pages = {77--131},
keywords = {software evolution, mining software repositories, multi-version analysis},
year = {2007},
}


@phdthesis{ku2008software,
  title={Software model-checking: Benchmarking and techniques for buffer overflow analysis},
  author={Ku, K.},
  year={2008},
  school={Citeseer}
}

@inproceedings{lu2005bugbench,
  title={Bugbench: Benchmarks for evaluating bug detection tools},
  author={Lu, S. and Li, Z. and Qin, F. and Tan, L. and Zhou, P. and Zhou, Y.},
 , year={2005}
}

@inproceedings{zanero2007flaws,
  title={Flaws and frauds in the evaluation of IDS/IPS technologies},
  author={Zanero, S.}
}

@TECHREPORT{Richmond05vise:a,
    author = {Michael Richmond},
    title = {ViSe: A virtual security testbed},
    institution = {},
    year = {2005}
}

@msthesis{kendall1999database,
  title={A database of computer attacks for the evaluation of intrusion detection systems},
  author={Kendall, K.},
  year={1999},
  school={Massachusetts Institute of Technology}
}

@article{wilander2002comparison,
  title={A comparison of publicly available tools for static intrusion prevention},
  author={Wilander, J. and Kamkar, M.},
  year={2002}
}

@msthesis{shelly2010using,
  title={Using a Web Server Test Bed to Analyze the Limitations of Web Application Vulnerability Scanners},
  author={Shelly, D.A.},
  year={2010},
  school={Virginia Polytechnic Institute and State University}
}

@inproceedings{securityopensource
,	author	= {Walden, James and Doyle, Maureen and Welch, Grant A. and Whelan, Michael}
,	title	= {Security of open source web applications}
,	booktitle	= {Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement}
,	year	= {2009}
,	pages	= {545--553}
,	publisher	= {IEEE Computer Society}
,	address	= {Washington, DC, USA}
,	series	= {ESEM '09}
,	isbn	= {978-1-4244-4842-5}
,	numpages	= {9}
,	url	= {http://dx.doi.org/10.1109/ESEM.2009.5314215}
,	doi	= {http://dx.doi.org/10.1109/ESEM.2009.5314215}
,	acmid	= {1671292}
}

@misc{
,	title	= {The Exploit Intelligence Project}
}

@techreport{shin2008towards
,	author	= {Shin, Y. and Williams, L.A.}
,	title	= {Towards a taxonomy of techniques to detect cross-site scripting and SQL injection vulnerabilities}
,	year	= {2008}
,	institution	= {North Carolina State University. Dept. of Computer Science}
}

@article{lippmann20001999,
  title={The 1999 DARPA off-line intrusion detection evaluation},
  author={Lippmann, R. and Haines, J.W. and Fried, D.J. and Korba, J. and Das, K.},
  journal={Computer Networks},
  volume={34},
  number={4},
  pages={579--595},
  year={2000},
  publisher={Elsevier}
}


@inproceedings{predictingvulnerablecomponents
,	author	= {Neuhaus, Stephan and Zimmermann, Thomas and Holler, Christian and Zeller, Andreas}
,	title	= {Predicting vulnerable software components}
,	booktitle	= {Proceedings of the 14th ACM conference on Computer and communications security}
,	year	= {2007}
,	pages	= {529--540}
,	publisher	= {ACM}
,	address	= {New York, NY, USA}
,	series	= {CCS '07}
,	isbn	= {978-1-59593-703-2}
,	location	= {Alexandria, Virginia, USA}
,	numpages	= {12}
,	url	= {http://doi.acm.org/10.1145/1315245.1315311}
,	doi	= {http://doi.acm.org/10.1145/1315245.1315311}
,	acmid	= {1315311}
,	keywords	= {prediction, software security}
}

@inproceedings{Dallmeier:2007:EBL:1321631.1321702,
 author = {Dallmeier, Valentin and Zimmermann, Thomas},
 title = {Extraction of bug localization benchmarks from history},
 booktitle = {Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering},
 series = {ASE '07},
 year = {2007},
 isbn = {978-1-59593-882-4},
 location = {Atlanta, Georgia, USA},
 pages = {433--436},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1321631.1321702},
 doi = {http://doi.acm.org/10.1145/1321631.1321702},
 acmid = {1321702},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {benchmarking, defect localization},
} 


@inproceedings{bufferoverflowbenchmark
,	author	= {Ku, Kelvin and Hart, Thomas E. and Chechik, Marsha and Lie, David}
,	title	= {A buffer overflow benchmark for software model checkers}
,	booktitle	= {Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering}
,	year	= {2007}
,	pages	= {389--392}
,	publisher	= {ACM}
,	address	= {New York, NY, USA}
,	series	= {ASE '07}
,	isbn	= {978-1-59593-882-4}
,	location	= {Atlanta, Georgia, USA}
,	numpages	= {4}
,	url	= {http://doi.acm.org/10.1145/1321631.1321691}
,	doi	= {http://doi.acm.org/10.1145/1321631.1321691}
,	acmid	= {1321691}
,	keywords	= {array bounds checking, benchmark, buffer overflow, model checking}
}

@inproceedings{frei2006large,
  title={Large-scale vulnerability analysis},
  author={Frei, S. and May, M. and Fiedler, U. and Plattner, B.},
  booktitle={Proceedings of the 2006 SIGCOMM workshop on Large-scale attack defense},
  pages={131--138},
  year={2006},
  organization={ACM}
}

@inproceedings{Bird:2009:FBB:1595696.1595716,
 author = {Bird, Christian and Bachmann, Adrian and Aune, Eirik and Duffy, John and Bernstein, Abraham and Filkov, Vladimir and Devanbu, Premkumar},
 title = {Fair and balanced?: bias in bug-fix datasets},
 booktitle = {Proceedings of the the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering},
 series = {ESEC/FSE '09},
 year = {2009},
 isbn = {978-1-60558-001-2},
 location = {Amsterdam, The Netherlands},
 pages = {121--130},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1595696.1595716},
 doi = {http://doi.acm.org/10.1145/1595696.1595716},
 acmid = {1595716},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {bias},
} 


@article{testingoverflows
,	author	= {Zitser, Misha and Lippmann, Richard and Leek, Tim}
,	title	= {Testing static analysis tools using exploitable buffer overflows from open source code}
,	journal	= {ACM SIGSOFT Softw. Eng. Notes}
,	year	= {2004}
,	volume	= {29}
,	pages	= {97--106}
,	month	= {October}
,	issue	= {6}
,	issn	= {0163-5948}
,	numpages	= {10}
,	url	= {http://doi.acm.org/10.1145/1041685.1029911}
,	doi	= {http://doi.acm.org/10.1145/1041685.1029911}
,	acmid	= {1029911}
,	publisher	= {ACM}
,	address	= {New York, NY, USA}
,	keywords	= {buffer overflow, evaluation, exploit, false alarm, security, source code, static analysis, test detection}
}

@inproceedings{Schmeelk:2010:TUF:1806672.1806684,
 author = {Schmeelk, Suzanna},
 title = {Towards a unified fault-detection benchmark},
 booktitle = {Proceedings of the 9th ACM SIGPLAN-SIGSOFT workshop on Program analysis for software tools and engineering},
 series = {PASTE '10},
 year = {2010},
 isbn = {978-1-4503-0082-7},
 location = {Toronto, Ontario, Canada},
 pages = {61--64},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1806672.1806684},
 doi = {http://doi.acm.org/10.1145/1806672.1806684},
 acmid = {1806684},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {benchmark, evaluation, quality assurance, software reliability},
} 


@article{classesvul
,	author	= {Meunier, P.}
,	title	= {Classes of Vulnerabilities and Attacks}
,	journal	= {Wiley Handbook of Science and Technology for Homeland Security}
,	year	= {2008}
,	publisher	= {Wiley Online Library}
}

